{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Single-Cell Resolution Analysis Pipeline for Neural Activity of Hydra Vulgaris** \n",
    "=============================================================\n",
    "*(Use with data from tdTomato_GCamP7 Animals)*\n",
    "\n",
    "Requires:\n",
    "-------------------------\n",
    "- Green and Red Channel Videos From 2-Color Confocal (GCaMP and tdTomato Channels)\n",
    "- Tracking Position Information From ICY Spot Tracking Protocol (Exported as CSV)\n",
    "- Conda Environment: Caiman_NOAH3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INPUT PATHS\n",
    "-----------------\n",
    "Enter paths to the appropriate files                    \n",
    "**Videos must be .avi (convert in imageJ if not)**     \n",
    "**Can also use a Tif sequence folder - change the read data function to Read_Data_TIFseq for this**    \n",
    "**If using windows**: Paths must start with an 'r' character: e.g. vid_path = **r**\"C:\\Users\\rylab\\ path to your file \\clip.avi\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block #1: define file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input path to your .csv from ICY\n",
    "csv_path = r\"C:\\Users\\rylab\\Desktop\\AliA\\Best 10X\\Best 10X_ICY.csv\"\n",
    "\n",
    "#input path to .avi of GCaMP Video\n",
    "vid_path = r\"C:\\Users\\rylab\\Desktop\\AliA\\Best 10X\\Substack (1-3000)_G7.avi\"\n",
    "\n",
    "#input path to .avi of tdTomato Video\n",
    "red_vid_path = r\"C:\\Users\\rylab\\Desktop\\AliA\\Best 10X\\Substack (1-3000)_tdT.avi\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SET UP DATA  \n",
    "-----------------------\n",
    "Run the following cells to set up the \n",
    "data to be analysed        \n",
    "**Set the FFmpeg path before running this cell**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block #2: import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing packages\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import skimage.io as iio\n",
    "import skvideo\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "#set this path to the FFmpegTool\\bin location on your machine (download FFmpeg if not already installed)\n",
    "#make sure to restart the kernel after setting the path\n",
    "skvideo.setFFmpegPath(r\"C:\\FFmpegTool\\bin\")\n",
    "\n",
    "import skvideo.io as io\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from caiman.source_extraction.cnmf import deconvolution as deconv\n",
    "from scipy.spatial.distance import cdist, pdist, euclidean\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy.cluster.hierarchy as shc\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "\n",
    "from collections import defaultdict\n",
    "from scipy.cluster.hierarchy import dendrogram, set_link_color_palette\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import rgb2hex, colorConverter\n",
    "from tqdm import tqdm\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block #3: define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining Functions - SHyGI Single-cell Hydra GCaMP Imaging package\n",
    "\n",
    "#Load data from specified paths\n",
    "def Read_Data(csv_path, vid_path, red_vid_path):\n",
    "    positions = (pd.read_csv(csv_path,usecols=['TrackID','t','x','y'])).values\n",
    "    vid = io.vread(vid_path)\n",
    "    red_vid = io.vread(red_vid_path)\n",
    "    return positions, vid, red_vid\n",
    "\n",
    "#Load data from specified folder of .tif files - Higher resolution but longer processing time\n",
    "def Read_Data_TIFseq(csv_path, vid_path, red_vid_path):\n",
    "    positions = (pd.read_csv(csv_path,usecols=['TrackID','t','x','y'])).values\n",
    "    vid = iio.ImageCollection(vid_path + '/*.tif')\n",
    "    red_vid = iio.ImageCollection(red_vid_path + '/*.tif')\n",
    "    return positions, vid, red_vid\n",
    "\n",
    "#ROI function\n",
    "def ROIextractor(frame,points,dim):\n",
    "    #why are these NOT already integers?? is it not pixel values?\n",
    "    x = int(points[0])\n",
    "    y = int(points[1])\n",
    "    row1 = x - dim\n",
    "    row2 = x + dim + 1\n",
    "    column1 = y - dim\n",
    "    column2 = y + dim + 1\n",
    "    ROI = frame[column1:column2,row1:row2]\n",
    "    return ROI \n",
    "\n",
    "#Filter Nematocytes\n",
    "#dead neuron and nematocyte removal function - removed tracks in the lowest set percentile of standard deviation\n",
    "#flaw is that it will remove neurons if there are no nematocytes recorded!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "def filt_nematocytes(intensities,percentile_threshold,positions):\n",
    "    std_devs = []\n",
    "    filtered_neurons = np.zeros((len(intensities),len(intensities[0])))\n",
    "    \n",
    "    for i in range(len(intensities)):\n",
    "        std_dev = np.std(intensities[i])\n",
    "        std_devs.append(std_dev)\n",
    "        \n",
    "    #lowest 20th percentile to find nematocytes    \n",
    "    std_range = (np.max(std_devs) - np.min(std_devs))\n",
    "    percentile = (std_range/100)\n",
    "    threshold = np.min(std_devs)+(percentile*percentile_threshold)\n",
    "    \n",
    "    for i in range(len(intensities)):\n",
    "        if std_devs[i] >= threshold:\n",
    "            filtered_neurons[i]=intensities[i]\n",
    "\n",
    "    filtered_neurons2 = []\n",
    "    positions2 = []\n",
    "    for i in range(len(filtered_neurons)):\n",
    "        if np.ndarray.tolist(filtered_neurons[i]) != np.ndarray.tolist(np.zeros(len(filtered_neurons[i]))):\n",
    "            filtered_neurons2.append(filtered_neurons[i])\n",
    "            print(i)\n",
    "            positions2.append(positions[i])\n",
    "            \n",
    "    return filtered_neurons2, positions2\n",
    "\n",
    "#Filters non-neuronal cells based on how well signals follow a gaussian distribution\n",
    "def Gaussian_noise_filter(intensities, alpha, positions):\n",
    "    new_data = []\n",
    "    positions_new = []\n",
    "    filtered_tracks = []\n",
    "    for i in range(len(intensities)):\n",
    "        a,b = sp.stats.normaltest(intensities[i])\n",
    "        if b >= alpha:\n",
    "            #follows normal dist\n",
    "            filtered_tracks.append(intensities[i])\n",
    "        elif b < alpha:\n",
    "            #does not follow normal dist\n",
    "            new_data.append(intensities[i])\n",
    "            positions_new.append(positions[i])\n",
    "    return new_data, positions_new, filtered_tracks\n",
    "\n",
    "#smoothing step\n",
    "def smoother(intensities, window):\n",
    "    N = window\n",
    "    filtered_data = []\n",
    "    for i in range(len(intensities)):\n",
    "        filtered_data.append(np.convolve(intensities[i], np.ones((N,))/N, mode='valid'))\n",
    "    return filtered_data\n",
    "\n",
    "#deltaF/F\n",
    "#following idea from the c.elegans paper on whole brain imaging\n",
    "def df_f(intensity):\n",
    "    df_f = []\n",
    "    for i in range(len(intensity)):\n",
    "        df_f_neuron = []\n",
    "        \n",
    "        #lowest 20th percentile used as base f\n",
    "        range_f = np.max(intensity[i]) - np.min(intensity[i])\n",
    "        percentile = range_f/100\n",
    "        percentile_boundary = 20\n",
    "        f_bkg = np.min(intensity[i])+(percentile*percentile_boundary)\n",
    "                           \n",
    "        #f = min(intensities[i])\n",
    "        #f = np.mean(intensities[i][0:10])\n",
    "        f = f_bkg\n",
    "        for j in range(len(intensity[0])):\n",
    "            df_f_frame = (intensity[i][j] - f)/f\n",
    "            df_f_neuron.append(df_f_frame)\n",
    "        df_f.append(df_f_neuron)\n",
    "    return df_f\n",
    "\n",
    "#deltaR/R\n",
    "def find_dR_R(intensities_green,intensities_red):\n",
    "    dR_R = []\n",
    "    for i in range(len(intensities_red)):\n",
    "        dR_R_neuron = []\n",
    "        \n",
    "        #create R array\n",
    "        R = np.zeros(len(intensities_red[i]))\n",
    "        for k in range(len(intensities_red[i])):\n",
    "            R[k] = intensities_green[i][k]/intensities_red[i][k]\n",
    "                     \n",
    "        #lowest 20th percentile used as base r (from C. Elegans Paper)\n",
    "        range_R = np.max(R) - np.min(R)\n",
    "        percentile = range_R/100\n",
    "        percentile_boundary = 20\n",
    "        R_bkg = np.min(R)+(percentile*percentile_boundary)\n",
    "\n",
    "        for j in range(len(intensities_red[i])):\n",
    "            dR_R_frame = ((R[j] - R_bkg)/R_bkg)\n",
    "            dR_R_neuron.append(dR_R_frame)\n",
    "        dR_R.append(dR_R_neuron)\n",
    "    return dR_R\n",
    "\n",
    "# #Deconvolution using ICA - code modified from 'Predicting natural behavior from whole-brain neural dynamics' by Scholz et al\n",
    "# def decorrelateNeuronsICA(R, G, tolerance):\n",
    "#     \"\"\"use PCA to remove covariance in Green and Red signals.\"\"\"\n",
    "#     R = np.asanyarray(R)\n",
    "#     G = np.asanyarray(G)\n",
    "#     Ynew = []\n",
    "#     ica = FastICA(n_components = 2, tol = tolerance)\n",
    "#     for li in range(len(R)):\n",
    "#         Y = np.vstack([R[li], G[li]]).T\n",
    "#         sclar2= StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "#         Y = sclar2.fit_transform(Y)\n",
    "#         S = ica.fit_transform(Y)\n",
    "#         # order components by max correlation with red signal\n",
    "#         v = [np.corrcoef(s,G[li])[0,1] for s in S.T]\n",
    "#         idn = np.argmin(np.abs(v))\n",
    "#         # check if signal needs to be inverted\n",
    "#         sign = np.sign(np.corrcoef(S[:,idn],R[li])[0,1])\n",
    "#         signal = sign*(S[:,idn])\n",
    "#         Ynew.append(signal)\n",
    "#     return np.array(Ynew)#, np.mean(var, axis=0), Rs, Gs \n",
    "\n",
    "def ICAdecorr(G, R, tolerance, repeats):\n",
    "    #edited function from Scholz et al to account for randomness of ICA by repeating multiple times and selecting best outcome\n",
    "    R = np.asanyarray(R)\n",
    "    G = np.asanyarray(G)\n",
    "    Ynew = []\n",
    "    for li in range(len(R)):\n",
    "        possible_outcomes = []\n",
    "        for k in range(repeats):\n",
    "            ica = FastICA(n_components = 2, tol = tolerance)\n",
    "            Y = np.vstack([G[li], R[li]]).T\n",
    "            sclar2= StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "            Y = sclar2.fit_transform(Y)\n",
    "            S = ica.fit_transform(Y)\n",
    "            # order components by max correlation with red signal\n",
    "            v = [np.corrcoef(s,R[li])[0,1] for s in S.T]\n",
    "            idn = np.argmin(np.abs(v))\n",
    "            # check if signal needs to be inverted\n",
    "            sign = np.sign(np.corrcoef(S[:,idn],G[li])[0,1])\n",
    "            signal = sign*(S[:,idn])\n",
    "            possible_outcomes.append(signal)\n",
    "        #best_outcome = possible outcome least correlated with the red signal (including anticorrelation)\n",
    "        correlations = []\n",
    "        for j in range(len(possible_outcomes)):\n",
    "            correlations.append(np.corrcoef(possible_outcomes[j], R[li])[0,1])\n",
    "        min_corr_index = np.argmin(np.abs(correlations))\n",
    "        best_outcome = possible_outcomes[min_corr_index]\n",
    "        Ynew.append(best_outcome)\n",
    "    return np.array(Ynew)\n",
    "\n",
    "#Normalise data between 0 and 1\n",
    "def norm_Data(data):\n",
    "    data_out = []\n",
    "    for i in range(len(data)):\n",
    "        data_out.append( (data[i] - min(data))/(max(data) - min(data)) )\n",
    "    return data_out\n",
    "\n",
    "#Normalise all trakcs in array between 0 and 1 \n",
    "def norm_all_data(data):\n",
    "    data_norm = []\n",
    "    for i in range(len(data)):\n",
    "        data_norm.append(norm_Data(data[i]))\n",
    "    return data_norm\n",
    "\n",
    "#reshaping the .csv to be analysed\n",
    "def reshaper(positions):\n",
    "    number_tracks = int(positions[len(positions)-1,0])\n",
    "    position_reshaped = []\n",
    "    for i in range(number_tracks):\n",
    "        if i%100 == 0:\n",
    "            print(i)\n",
    "        positions_track = []\n",
    "        for j in range(len(positions)):\n",
    "            if positions[j,0] == i:\n",
    "                positions_track.append(positions[j,2:4])\n",
    "        position_reshaped.append(positions_track)\n",
    "    posit = np.asanyarray(position_reshaped) \n",
    "    return posit\n",
    "\n",
    "#Possibly faster untested reshaper function\n",
    "def fastreshaper(positions):\n",
    "    number_tracks = int(positions[len(positions)-1,0])\n",
    "    number_frames = int(max(positions[:,1])+1)\n",
    "    position_reshaped = np.zeros([number_tracks, number_frames, 2])\n",
    "    for i in range(number_tracks):\n",
    "        positions_track = np.zeros([number_frames, 2])\n",
    "        frame_count = 0\n",
    "        for j in range(len(positions)):\n",
    "            if positions[j,0] == i:\n",
    "                positions_track[frame_count] = positions[j,2:4]\n",
    "                frame_count += 1\n",
    "        position_reshaped[i] = positions_track\n",
    "    posit = np.asanyarray(position_reshaped) \n",
    "    return posit\n",
    "\n",
    "#removing incomplete tracks\n",
    "def remove_incomplete_tracks(posit, num_frames):\n",
    "    posit_corrected = []\n",
    "    for i in range(len(posit)):\n",
    "        if len(posit[i]) == num_frames:\n",
    "            posit_corrected.append(posit[i])\n",
    "    return posit_corrected\n",
    "\n",
    "#extract ROI throughout the video and record intensities\n",
    "def Extract_Fluorescence(position_corrected, video, dimention):\n",
    "    dim = dimention\n",
    "    vid = video\n",
    "    posit_corrected = position_corrected\n",
    "    num_frames = len(posit_corrected[0])\n",
    "    intensities = []\n",
    "    #needs to update position array as some fluorescence tracks may be dropped here \n",
    "    position_updated = []\n",
    "    pbar = tqdm(total=len(posit_corrected))\n",
    "    for track in range(len(posit_corrected)):\n",
    "        intensity = []\n",
    "        break_count = 0\n",
    "       # print(track)\n",
    "        for frame in range(num_frames):\n",
    "            area = ROIextractor(vid[frame],posit_corrected[track][frame],dim)\n",
    "            near_edge = False\n",
    "            if len(area[0]) != 2*dim + 1 or len(area[1]) != 2*dim + 1:\n",
    "                near_edge = True #np.isnan(np.mean(area))\n",
    "            if near_edge == True:\n",
    "                #print('break')\n",
    "                break_count += 1\n",
    "                break\n",
    "            else:\n",
    "                intensity.append(np.mean(area))\n",
    "        if break_count == 0:\n",
    "            intensities.append(intensity)\n",
    "            position_updated.append(position_corrected[track])\n",
    "            \n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "            \n",
    "#             else:\n",
    "#                 dim_count = 1\n",
    "#                 while np.isnan(np.mean(area)) == True and dim-dim_count > dim/2:\n",
    "#                     area = ROIextractor(vid[frame],posit_corrected[track][frame],dim-dim_count)\n",
    "#                     dim_count += 1\n",
    "#                 if dim-dim_count > dim/2:\n",
    "#                     intensity.append(np.mean(area))\n",
    "#                 else:\n",
    "#                     break_count = 1\n",
    "#                     break\n",
    "        #if break_count == 0:\n",
    "             \n",
    "    return intensities, position_updated\n",
    "\n",
    "#extract ROI throughout the video and record intensities\n",
    "def Extract_Fluorescence_corrected(position_corrected, video, dimention):\n",
    "    dim = dimention\n",
    "    vid = video\n",
    "    posit_corrected = position_corrected\n",
    "    num_frames = len(posit_corrected[0])\n",
    "    intensities = []\n",
    "    #needs to update position array as some fluorescence tracks may be dropped here \n",
    "    position_updated = []\n",
    "    track = 0\n",
    "    pbar = tqdm(total=len(posit_corrected))\n",
    "    while track < len(posit_corrected):\n",
    "        try:\n",
    "            intensity = []\n",
    "            break_count = 0\n",
    "            #print(track)\n",
    "            for frame in range(num_frames):\n",
    "                area = ROIextractor(vid[frame],posit_corrected[track][frame],dim)\n",
    "                near_edge = False\n",
    "                if len(area[0]) != 2*dim + 1 or len(area[1]) != 2*dim + 1:\n",
    "                    near_edge = True #np.isnan(np.mean(area))\n",
    "                if near_edge == True:\n",
    "                    #print('break')\n",
    "                    break_count += 1\n",
    "                    break\n",
    "                else:\n",
    "                    intensity.append(np.mean(area))\n",
    "            if break_count == 0:\n",
    "                intensities.append(intensity)\n",
    "                position_updated.append(position_corrected[track])\n",
    "            \n",
    "            track += 1\n",
    "            \n",
    "        except:\n",
    "            #print('problematic neruon removed: ',track)\n",
    "            posit_corrected = np.delete(posit_corrected,[track],0)\n",
    "            \n",
    "        pbar.update(1)\n",
    "    \n",
    "    pbar.close()\n",
    "            \n",
    "#             else:\n",
    "#                 dim_count = 1\n",
    "#                 while np.isnan(np.mean(area)) == True and dim-dim_count > dim/2:\n",
    "#                     area = ROIextractor(vid[frame],posit_corrected[track][frame],dim-dim_count)\n",
    "#                     dim_count += 1\n",
    "#                 if dim-dim_count > dim/2:\n",
    "#                     intensity.append(np.mean(area))\n",
    "#                 else:\n",
    "#                     break_count = 1\n",
    "#                     break\n",
    "        #if break_count == 0:\n",
    "             \n",
    "    return intensities, position_updated\n",
    "\n",
    "#show all tracking info on neuron\n",
    "def full_eval(neuron, signal, eval_frame, dim, posit_corrected):\n",
    "    #intensity over time plot of the neuron\n",
    "    plt.plot(signal[neuron])\n",
    "    plt.show()\n",
    "\n",
    "    #neuron in ROI\n",
    "    plt.imshow(ROIextractor(vid[eval_frame],posit_corrected[neuron][eval_frame],dim))\n",
    "    plt.show()\n",
    "\n",
    "    #position of neuron on animal at set frame\n",
    "    plt.imshow(vid[eval_frame])\n",
    "    plt.scatter(posit_corrected[neuron][eval_frame][0],posit_corrected[neuron][eval_frame][1], edgecolors = 'r',facecolors='none')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_all(input_array):\n",
    "    for i in range(len(input_array)):\n",
    "        plt.figure(i)\n",
    "        plt.plot(input_array[i])\n",
    "        plt.title(i)\n",
    "    plt.show()\n",
    "    \n",
    "#heatmap plotting\n",
    "def plot_heatmap(dataset, title, scale):\n",
    "    fig, axs = plt.subplots(1,1)\n",
    "    heatmap_neurons = plt.imshow(dataset, aspect = 'auto', origin = 'lower')\n",
    "    plt.xlabel('Frame')\n",
    "    plt.ylabel('Neuron')\n",
    "    plt.title(title)\n",
    "    cbar = plt.colorbar(heatmap_neurons, ax=axs, orientation='vertical', fraction=.1)\n",
    "    cbar.set_label(scale, rotation = '-90', labelpad = 15)\n",
    "    cbar.minorticks_on()\n",
    "    plt.show()\n",
    "    \n",
    "#detrends single neuron's trace - used to evaluate ideal polynomial degree\n",
    "#polynomial of degree 17 works well as starting point\n",
    "def detrend(data, polynomial_degree):\n",
    "    x_vals = np.arange(len(data))\n",
    "    coeffs = np.polyfit(x_vals, data, polynomial_degree)\n",
    "    polynomial = np.polyval(coeffs, x_vals)\n",
    "    new_sequence = data - polynomial\n",
    "    return new_sequence\n",
    "\n",
    "#detrendes all data in array\n",
    "def detrend_all(input_array, polynomial_degree):\n",
    "    detrended = []\n",
    "    poly_deg = polynomial_degree\n",
    "    for i in range(len(input_array)):\n",
    "        detrended.append(detrend(input_array[i], poly_deg))\n",
    "    return detrended\n",
    "\n",
    "#superimpose ROI onto video frame\n",
    "def Super_impose(video, frame_to_view, Title):\n",
    "    vid = video\n",
    "    plt.imshow(vid[frame_to_view])\n",
    "    for track in range(len(posit_corrected)):\n",
    "        plt.scatter(posit_corrected[track][frame_to_view][0],posit_corrected[track][frame_to_view][1], edgecolors = 'r',facecolors='none')\n",
    "    plt.title(Title)\n",
    "    plt.show()\n",
    "    \n",
    "#Super impose locations of neurons in specific cluster onto video\n",
    "def Super_impose_cluster(video, frame_to_view, posit_corrected, clusters, cluster_to_view, Title, sequence, color_codes):\n",
    "    vid = video\n",
    "    cluster_index = []\n",
    "    \n",
    "    for i in range(len(clusters)):\n",
    "        if clusters[i] in cluster_to_view:\n",
    "            cluster_index.append(i)\n",
    "            \n",
    "    for k in range(sequence):\n",
    "        \n",
    "        fig = plt.figure(dpi=100)\n",
    "        plt.imshow(vid[frame_to_view+k])\n",
    "    \n",
    "        for track in cluster_index:\n",
    "            plt.scatter(posit_corrected[track][frame_to_view+k][0],posit_corrected[track][frame_to_view+k][1]\\\n",
    "                        , edgecolors = color_codes[track],facecolors='none')\n",
    "\n",
    "        plt.title(Title)\n",
    "        \n",
    "        if k == 0:\n",
    "            plt.show()\n",
    "            \n",
    "        png1 = BytesIO()\n",
    "        fig.savefig(png1, format='jpeg')\n",
    "        # (2) load this image into PIL\n",
    "        png2 = Image.open(png1)\n",
    "        # (3) save as TIFF\n",
    "        png2.save('seq'+str(k)+'.tiff')\n",
    "        png1.close()\n",
    "        plt.close(fig)\n",
    "\n",
    "    \n",
    "\n",
    "#Uses FOOPSI algrorithm from CAIMAN package to decompose calcium signal and estimate neural spikes\n",
    "def FOOPSI_all(detrended_data):\n",
    "    detrended = detrended_data\n",
    "    spikes_signal_dR = np.zeros((len(detrended),len(detrended[1])))\n",
    "    ca_foopsi_traces = np.zeros((len(detrended),len(detrended[1])))\n",
    "    for i in range(len(detrended)):\n",
    "        ca_foopsi,cb,b1,g,c1,spikes_foopsi,lam = deconv.constrained_foopsi(np.asanyarray(detrended[i]),p=2)\n",
    "        spikes_signal_dR[i] = spikes_foopsi\n",
    "        ca_foopsi_traces[i] = ca_foopsi\n",
    "    return ca_foopsi_traces, spikes_signal_dR\n",
    "\n",
    "#Uses FOOPSI spike information to generate an array to be plotted as a raster plot\n",
    "def Find_Raster(foopsi_spikes, threshold):\n",
    "    spikes_signal_dR = foopsi_spikes\n",
    "    spike_thresh_dR = threshold\n",
    "    raster_array_dR = np.zeros((len(spikes_signal_dR),len(spikes_signal_dR[1])))\n",
    "    for i in range(len(spikes_signal_dR)):\n",
    "        for j in range(len(spikes_signal_dR[i])):\n",
    "            if max(spikes_signal_dR[i]) > 0:\n",
    "                if spikes_signal_dR[i][j] >= spike_thresh_dR: #*np.mean(spikes_signal_dR[i]):\n",
    "                    raster_array_dR[i][j] = j\n",
    "    return raster_array_dR\n",
    "\n",
    "def Find_Raster_adaptive(foopsi_spikes, ratio):\n",
    "    spikes_signal_dR = foopsi_spikes\n",
    "    raster_array_dR = np.zeros((len(spikes_signal_dR),len(spikes_signal_dR[1])))\n",
    "    pbar = tqdm(total=len(spikes_signal_dR))\n",
    "    for i in range(len(spikes_signal_dR)):\n",
    "        spike_thresh_dR = np.max(spikes_signal_dR[i])*ratio\n",
    "        for j in range(len(spikes_signal_dR[i])):\n",
    "            if max(spikes_signal_dR[i]) > 0:\n",
    "                if spikes_signal_dR[i][j] >= spike_thresh_dR: #*np.mean(spikes_signal_dR[i]):\n",
    "                    raster_array_dR[i][j] = j\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "    return raster_array_dR\n",
    "\n",
    "#extract clusters from dendogram\n",
    "#borrowed from wed (datanongrata.com)\n",
    "def give_cluster_assigns(df, numclust, transpose):\n",
    "    if transpose==True:\n",
    "        data_dist = df\n",
    "        data_link = shc.linkage(data_dist.corr(), method='ward')\n",
    "        cluster_assigns=pd.Series(shc.fcluster(data_link, numclust, criterion='maxclust', monocrit=None), index=df.columns)\n",
    "    else:\n",
    "        data_dist = pdist(df)\n",
    "        data_link = shc.linkage(data_dist, metric = 'correlation', method='ward')\n",
    "        cluster_assigns=pd.Series(shc.fcluster(data_link, numclust, criterion='maxclust', monocrit=None), index=df.index)\n",
    "    return cluster_assigns\n",
    "\n",
    "#show all tracking info on neuron\n",
    "def single_neuron_investigation(neuron, signal, video, eval_frame, dim, posit_corrected):\n",
    "    print('Neuron: ', neuron)\n",
    "    \n",
    "    #intensity over time plot of the neuron\n",
    "    plt.plot(signal[neuron])\n",
    "    plt.title('Detrended Calcuim Signal')\n",
    "    plt.show()\n",
    "    \n",
    "    #Raster plot of neuron\n",
    "    plt.eventplot(raster_array_dR[neuron],linelengths = 0.6)\n",
    "    plt.xlim((1,len(raster_array_dR[neuron])))\n",
    "    plt.title('Raster Plot of Neuron')\n",
    "    plt.show()\n",
    "\n",
    "    #neuron in ROI\n",
    "    plt.imshow(ROIextractor(vid[eval_frame],posit_corrected[neuron][eval_frame],dim))\n",
    "    plt.title('Neuron ROI')\n",
    "    plt.show()\n",
    "\n",
    "    #position of neuron on animal at set frame\n",
    "    plt.imshow(vid[eval_frame])\n",
    "    plt.scatter(posit_corrected[neuron][eval_frame][0],posit_corrected[neuron][eval_frame][1], edgecolors = 'r',facecolors='none')\n",
    "    plt.title('Neuron Position on Hydra')\n",
    "    plt.show()\n",
    "\n",
    "#create a 2D gaussian kernel\n",
    "def gkern(kernlen, nsig):\n",
    "    'from stack overflow'\n",
    "    \"\"\"Returns a 2D Gaussian kernel.\"\"\"\n",
    "\n",
    "    x = np.linspace(-nsig, nsig, kernlen+1)\n",
    "    kern1d = np.diff(sp.stats.norm.cdf(x))\n",
    "    kern2d = np.outer(kern1d, kern1d)\n",
    "    return kern2d/kern2d.sum()\n",
    "\n",
    "#extraction of intensity from single neuron within ROI\n",
    "def SingleCellIntensity(neuron, video, positions, dimentionROI, Circle_radius, distance_threshold, display_on = False):\n",
    "    display = []\n",
    "    mask_circle_radius = Circle_radius - 0\n",
    "    neuron_points = []\n",
    "    intensities = []\n",
    "    positions_corrected = []\n",
    "    backframes = 10\n",
    "    past_thresh = 3\n",
    "    for frame in range(len(video)):\n",
    "        #print('Frame: ', frame)\n",
    "        #Load raw image and copy to avoid affecting the original video\n",
    "        raw_image = ROIextractor(video[frame],positions[neuron][frame], dimentionROI)\n",
    "        image = raw_image.copy()\n",
    "        \n",
    "        #correction for ROI leaving field\n",
    "        dim_image = np.min(image.shape[0:1])\n",
    "        #print(dim_image)\n",
    "        if dim_image < 5:\n",
    "            dim_image = 5\n",
    "        #print(dim_image)\n",
    "        image = image[0:dim_image, 0:dim_image]\n",
    "        #print(image)\n",
    "        #print(image.shape[:])\n",
    "        #Convert to grayscale\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        #Copy Image pre processing to use for finding final intensity value from \n",
    "        image_out = image.copy()\n",
    "        image_display = image.copy()\n",
    "        #Create Gaussian Kernel to make points close to the centre appear brighter than points on the edges\n",
    "        kernel_gauss = gkern(image.shape[0], 0.7)\n",
    "        #print(frame)\n",
    "        image = kernel_gauss*image\n",
    "        #find Centre Point of the image to use as starting point for finding neuron\n",
    "        centrept = [int(len(image[0])/2), int(len(image[1])/2)]\n",
    "\n",
    "        if frame == 0:\n",
    "            #find first 3 highest pixels highest pixel\n",
    "            highpt_prev = centrept\n",
    "            highpts = []\n",
    "            distances = []\n",
    "            for k in range(4):\n",
    "                image = cv2.GaussianBlur(image, (5,5), 0)\n",
    "                low,high,lowpt,highpt = cv2.minMaxLoc(image)\n",
    "                highpts.append(highpt)\n",
    "                \n",
    "                #add brighness coefficient to couteract possibility of darker point near centre\n",
    "                if high == 0:\n",
    "                    high = 0.1\n",
    "                bright_coeff = (1/high)*0.5\n",
    "            \n",
    "                cv2.circle(image, highpt, Circle_radius, 0, -1)\n",
    "\n",
    "                distances.append(bright_coeff*euclidean(highpts[k], highpt_prev))\n",
    "            \n",
    "            #take point closest to centre    \n",
    "            mindist = np.argmin(distances)\n",
    "            neuronpt = highpts[mindist]\n",
    "\n",
    "        elif frame > 0:\n",
    "            image = cv2.GaussianBlur(image, (5,5), 0)\n",
    "            low,high,lowpt,highpt = cv2.minMaxLoc(image)\n",
    "            distance = euclidean(highpt, highpt_prev)\n",
    "            \n",
    "            if frame < backframes:\n",
    "                if distance <= distance_threshold:\n",
    "                    neuronpt = highpt\n",
    "\n",
    "                elif distance > distance_threshold:\n",
    "                    for k in range(3):\n",
    "                        cv2.circle(image, highpt, Circle_radius, 0, -1)\n",
    "                        image = cv2.GaussianBlur(image, (5,5), 0)\n",
    "                        low,high,lowpt,highpt = cv2.minMaxLoc(image)\n",
    "                        distance = euclidean(highpt, highpt_prev)\n",
    "                        if distance <= distance_threshold:\n",
    "                            neuronpt = highpt\n",
    "                            break\n",
    "                \n",
    "            else:\n",
    "                distance_past = euclidean(highpt, neuron_points[frame-backframes])\n",
    "                \n",
    "                if distance <= distance_threshold and distance_past <= past_thresh:\n",
    "                    neuronpt = highpt\n",
    "                    \n",
    "                if distance > distance_threshold:\n",
    "#                     print('thresh1')\n",
    "                    for k in range(3):\n",
    "                        cv2.circle(image, highpt, Circle_radius-1, 0, -1)\n",
    "                        image = cv2.GaussianBlur(image, (5,5), 0)\n",
    "                        low,high,lowpt,highpt = cv2.minMaxLoc(image)\n",
    "                        distance = euclidean(highpt, highpt_prev)\n",
    "                        if distance <= distance_threshold:\n",
    "                            neuronpt = highpt\n",
    "                            distance_past = euclidean(highpt, neuron_points[frame-backframes])\n",
    "                            break\n",
    "                \n",
    "                if distance_past > past_thresh: # and distance <= distance_threshold:\n",
    "#                     print('past')\n",
    "                    neuronpt = neuron_points[frame-2]\n",
    "\n",
    "        #save_values for next iteration                \n",
    "        highpt_prev = neuronpt\n",
    "        neuron_points.append(neuronpt)\n",
    "#         print('npt ',neuronpt)\n",
    "\n",
    "        #extract fluorescence within selected circle\n",
    "        circle_mask = np.zeros((image_out.shape[0],image_out.shape[1]),dtype = np.uint8)\n",
    "        cv2.circle(circle_mask, neuronpt, mask_circle_radius, 255, -1)\n",
    "        \n",
    "        if display_on == True:\n",
    "            image_display = cv2.GaussianBlur(image_display, (5,5), 0) \n",
    "            cv2.circle(image_display, neuronpt, Circle_radius, 255)\n",
    "            plt.imshow(image_display)\n",
    "            plt.show()\n",
    "            display.append(image_display)\n",
    "        \n",
    "        image_out = cv2.GaussianBlur(image_out, (5,5), 0)\n",
    "        mean = np.max(cv2.mean(image_out, mask=circle_mask))\n",
    "#         print('mean: ', mean)\n",
    "#         print('max: ', np.max(image_out))\n",
    "        intensities.append(mean)\n",
    "        positions_corrected.append(posit_corrected)\n",
    "    if display_on == True:\n",
    "        return intensities, positions_corrected, neuron_points, display\n",
    "    else:\n",
    "        return  intensities, positions_corrected, neuron_points\n",
    "\n",
    "#red single cell ROI\n",
    "def Red_SingleCellIntensity(neuron, points, vid_red, dim, positions, Circle_radius):\n",
    "    images_out = []\n",
    "    intensities = []\n",
    "    mask_circle_radius = Circle_radius - 0\n",
    "    for frame in range(len(points)):\n",
    "        raw_image_red = ROIextractor(vid_red[frame],positions[neuron][frame], dim)\n",
    "        image_red = raw_image_red.copy()\n",
    "        \n",
    "        #correction for ROI leaving field\n",
    "        dim_image = np.min(image_red.shape[0:1])\n",
    "        image_red = image_red[0:dim_image, 0:dim_image]\n",
    "        \n",
    "         #extract fluorescence within selected circle\n",
    "        circle_mask = np.zeros((image_red.shape[0],image_red.shape[1]),dtype = np.uint8)\n",
    "        cv2.circle(circle_mask, points[frame], mask_circle_radius, 255, -1)\n",
    "        \n",
    "        image_display = cv2.GaussianBlur(image_red, (5,5), 0) \n",
    "        cv2.circle(image_display, points[frame], Circle_radius, 255)\n",
    "#         plt.imshow(image_display)\n",
    "#         images_out.append(image_display)\n",
    "#         plt.show()\n",
    "        \n",
    "        image_out = cv2.GaussianBlur(image_red, (5,5), 0)\n",
    "        mean = np.max(cv2.mean(image_out, mask=circle_mask))\n",
    "#         plt.imshow(image_out)\n",
    "#         plt.show()\n",
    "#         print('mean: ', mean)\n",
    "#         print('max: ', np.max(image_out))\n",
    "        intensities.append(mean)\n",
    "    return intensities#, images_out\n",
    "\n",
    "#intensities from all individual neurons\n",
    "def SingleCellIntensities(video, positions, dimentionROI, Circle_radius, distance_threshold):\n",
    "\n",
    "    '''Must Run the Extract_Fluorescence function before the SingleCellIntensities function as you need \n",
    "    to use the updated 'posit_corrected' output from Extract_Fluorescence as the positions for \n",
    "    SingleCellIntensities as it has no feature to correct this itself'''\n",
    "\n",
    "    intensities = []\n",
    "    position_updated = []\n",
    "    all_points = []\n",
    "    for track in range(len(positions)):\n",
    "        print(track)\n",
    "        intensity, posits_corr,points = SingleCellIntensity(track, video, positions, dimentionROI, Circle_radius, distance_threshold)\n",
    "        intensities.append(intensity)\n",
    "        position_updated.append(positions[track])\n",
    "        all_points.append(points)\n",
    "    return intensities, position_updated, all_points\n",
    "\n",
    "#intensities from all individual neurons\n",
    "def SingleCellIntensities_corrected(video, positions, dimentionROI, Circle_radius, distance_threshold):\n",
    "\n",
    "    '''Must Run the Extract_Fluorescence function before the SingleCellIntensities function as you need \n",
    "    to use the updated 'posit_corrected' output from Extract_Fluorescence as the positions for \n",
    "    SingleCellIntensities as it has no feature to correct this itself'''\n",
    "\n",
    "    intensities = []\n",
    "    position_updated = []\n",
    "    all_points = []\n",
    "    track = 0\n",
    "    pbar = tqdm(total=len(positions))\n",
    "    while track < len(positions):\n",
    "        try:\n",
    "            #print(track)\n",
    "            intensity, posits_corr,points = SingleCellIntensity(track, video, positions, dimentionROI, Circle_radius, distance_threshold)\n",
    "            intensities.append(intensity)\n",
    "            position_updated.append(positions[track])\n",
    "            all_points.append(points)\n",
    "            track += 1\n",
    "            \n",
    "        except:\n",
    "            del positions[track]\n",
    "            #print('problematic neruon removed: ',track)\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "            \n",
    "    return intensities, position_updated, all_points\n",
    "\n",
    "#intensities from all individual red channels\n",
    "def SingleCellIntensities_Red(video_red, all_points, positions, dimentionROI, Circle_radius):\n",
    "    intensities_red = []\n",
    "    for track in range(len(positions)):\n",
    "        intensity = Red_SingleCellIntensity(track, all_points[track], video_red, dimentionROI, positions, Circle_radius)\n",
    "        intensities_red.append(intensity)\n",
    "    return intensities_red\n",
    "\n",
    "def rapid_reshaper(positions, num_frames, start):\n",
    "    \n",
    "    complete_tracks = []\n",
    "    i = 0\n",
    "    frame_counter = 0\n",
    "    all_lines = positions.shape[0]\n",
    "    position_reshaped = []\n",
    "    positions_track = []\n",
    "    positions = np.vstack((positions,positions[0,:]))\n",
    "\n",
    "    while i < all_lines:\n",
    "   \n",
    "        if positions[i,0] == positions[i+1,0] and positions[i,1] >= start:\n",
    "            frame_counter += 1\n",
    "            positions_track.append(positions[i,2:4])\n",
    "        else:\n",
    "            if frame_counter == num_frames - start - 1:\n",
    "                positions_track.append(positions[i,2:4])\n",
    "                complete_tracks.append(positions[i,0])\n",
    "                position_reshaped.append(positions_track)\n",
    "            \n",
    "            positions_track = []\n",
    "            frame_counter = 0\n",
    "\n",
    "        i += 1\n",
    "            \n",
    "    posit = np.asanyarray(position_reshaped)        \n",
    "    print(\"Number of fully tracked neurons: \",len(complete_tracks))\n",
    "    return posit\n",
    "\n",
    "def rapid_reshaper_MW(positions, num_frames, window_size):\n",
    "    \n",
    "    frames_dist = np.zeros(num_frames-window_size+1)\n",
    "    all_lines = positions.shape[0]\n",
    "    positions = np.vstack((positions,positions[0,:]))\n",
    "    break_val = 0\n",
    "    for j in range(num_frames-window_size+1):\n",
    "        \n",
    "        if j% 100 == 0:\n",
    "            print(j)\n",
    "        window = range(j,window_size)\n",
    "        complete_tracks = []\n",
    "        i = 0\n",
    "        frame_counter = 0\n",
    "        while i < all_lines:\n",
    "             \n",
    "            if positions[i,0] == positions[i+1,0] and positions[i,1] >= j:\n",
    "                frame_counter += 1     \n",
    "            else:\n",
    "                if frame_counter == num_frames - j - 1:\n",
    "                    complete_tracks.append(positions[i,0])\n",
    "\n",
    "                frame_counter = 0\n",
    "\n",
    "            i += 1\n",
    "            \n",
    "        frames_dist[j] = len(complete_tracks)\n",
    "        #print(len(complete_tracks), j)\n",
    "        if frames_dist[j] < break_val:\n",
    "            break\n",
    "        break_val = frames_dist[j]\n",
    "    \n",
    "    max_tracked = max(frames_dist)\n",
    "    return max_tracked, np.where(frames_dist == max_tracked)\n",
    "\n",
    "class Clusters(dict):\n",
    "    def _repr_html_(self):\n",
    "        html = '<table style=\"border: 0;\">'\n",
    "        for c in self:\n",
    "            hx = rgb2hex(colorConverter.to_rgb(c))\n",
    "            html += '<tr style=\"border: 0;\">' \\\n",
    "            '<td style=\"background-color: {0}; ' \\\n",
    "                       'border: 0;\">' \\\n",
    "            '<code style=\"background-color: {0};\">'.format(hx)\n",
    "            html += c + '</code></td>'\n",
    "            html += '<td style=\"border: 0\"><code>' \n",
    "            html += repr(self[c]) + '</code>'\n",
    "            html += '</td></tr>'\n",
    "        \n",
    "        html += '</table>'\n",
    "        \n",
    "        return html\n",
    "\n",
    "\n",
    "def get_cluster_classes(den, label='ivl'):\n",
    "    cluster_idxs = defaultdict(list)\n",
    "    for c, pi in zip(den['color_list'], den['icoord']):\n",
    "        for leg in pi[1:3]:\n",
    "            i = (leg - 5.0) / 10.0\n",
    "            if abs(i - int(i)) < 1e-5:\n",
    "                cluster_idxs[c].append(int(i))\n",
    "    \n",
    "    cluster_classes = Clusters()\n",
    "    for c, l in cluster_idxs.items():\n",
    "        i_l = [den[label][i] for i in l]\n",
    "        cluster_classes[c] = i_l\n",
    "    \n",
    "    for c, l in cluster_idxs.items():\n",
    "        cluster_classes[c] = set(cluster_classes[c])\n",
    "        \n",
    "    return cluster_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block #4: read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in data\n",
    "positions, vid, red_vid = Read_Data(csv_path, vid_path, red_vid_path)\n",
    "#Get Information About Raw Data\n",
    "num_frames = len(vid)\n",
    "num_red_frames = len(red_vid)\n",
    "num_tracks = int(positions[-1,0])\n",
    "#Display Information\n",
    "print('Numer of Frames in Green Video:', num_frames)\n",
    "print('Number of Frames in Red Video:', num_red_frames)\n",
    "print('Number of Points Tracked by ICY:', num_tracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block #5: reshape using a moving window (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "window_size = 2500\n",
    "max_tracked, max_index = rapid_reshaper_MW(positions, num_frames, window_size)\n",
    "max_index = max_index[-1]\n",
    "print(max_tracked, max_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block #6: reshape using a pre-defined starting point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_index = 500\n",
    "posit_corrected = rapid_reshaper(positions, num_frames, start = max_index)\n",
    "vid = vid[max_index:]\n",
    "red_vid = red_vid[max_index:] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CALCIUM SIGNAL EXTRACTION\n",
    "------------------------\n",
    "These following cells will remove neurons that were not completely tracked throughout the video, extract a region of interest around each fully tracked neuron, and extract the intensity of each neuron throughout the video and plot the raw intensities. The signal can then be corrected for motion artefacts by finding the ratiometric signal between the green and red channels - dR/R; or through the use of Independant Component Analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Following 2 Cells may Give a Runtime Warning - This is Fine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block #7: extract calcium siganls and correct for motion artefacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Extract the fluorescence intensity in the GCaMP channel throughout the video for each neuron\n",
    "\n",
    "#size of ROI\n",
    "dim = 4\n",
    "intensities, posit_corrected = Extract_Fluorescence_corrected(posit_corrected, vid, dimention = dim)\n",
    "\n",
    "intensities, posit_corrected, neuron_pts = SingleCellIntensities_corrected(vid, posit_corrected, dim, 4, 4)\n",
    "\n",
    "#Extract the fluorescence intensity in the Red channel throughout the video for each neuron\n",
    "intensities_red, posit_corrected = Extract_Fluorescence(posit_corrected, red_vid, dim)\n",
    "\n",
    "#plot raw neuronal intensities & display number of fully tracked neurons\n",
    "number_of_neurons = len(intensities)\n",
    "print('number of neurons = ', number_of_neurons)\n",
    "\n",
    "for track in range(len(intensities)):\n",
    "    plt.plot(intensities[track])\n",
    "    plt.title('Raw GCaMP Intensity plots of all sufficiently recorded neurons')\n",
    "    plt.xlabel('Frame')\n",
    "    plt.ylabel('Intenstiy')\n",
    "plt.show()\n",
    "\n",
    "#Plot intensities of red channels - used to identify motion artefacts and leaking between channels\n",
    "for track in range(len(intensities)):\n",
    "    plt.plot(intensities_red[track])\n",
    "    plt.title('Intensity Plot of Red Channel')\n",
    "    plt.xlabel('Frame')\n",
    "    plt.ylabel('Neuron')\n",
    "    \n",
    "#DeltaR/R or ICA used to correct for motion artefacts and cross channel leaking\n",
    "#Obtain Artefact Free Ca Signal\n",
    "CaSignal = ICAdecorr(intensities, intensities_red, 0.5, 10)\n",
    "\n",
    "#Plot Signal\n",
    "for i in range(len(CaSignal)):\n",
    "    plt.plot(CaSignal[i])\n",
    "plt.title('Extracted Calcium Signal Plot')\n",
    "plt.xlabel('Frame')\n",
    "plt.ylabel('Ca Intensity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block #8: plot heatmap of Calcium Signal (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Heatmap of Calcium Signal\n",
    "#can normalise here for better signal...\n",
    "plot_heatmap(CaSignal, 'Heatmap of Extracted Calcium Signal', 'Ca Signal Intensity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcium Signal Extraction - Optional Cells\n",
    "--------------------------\n",
    "**These Cells Dont Need to be Run**          \n",
    "Cells for evaluating performance or saving preliminary results        \n",
    "Only Run the Cells you want to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional Cells to Evaluate ROI Tracking**      \n",
    "Input frame number to view all of the ROIs tracked in that frame      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block #9: super-impose ROIs on video frame in both channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#superimpose ROIs on video frame in both channels\n",
    "\n",
    "#select frame to view\n",
    "frame_to_view = 1606\n",
    "\n",
    "Super_impose(vid, frame_to_view, 'Neuron Tracking in Green Channel')\n",
    "Super_impose(red_vid, frame_to_view, 'Neuron Tracking in Red Channel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional Cells to Evaluate Effect and Correction of Motion Artifacts and Red Leakage**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block #10: plot all motion-corrected GCaMP intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Raw Transients in Green\n",
    "plot_all(intensities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block #11 plot red transient signal to check for motion artefacts and leaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Red Transient to check for motion artefacts and leaking\n",
    "Neuron_with_possible_artefact = 11\n",
    "\n",
    "plt.figure(1)\n",
    "plt.title('Raw Red Channel Plot')\n",
    "plt.plot(intensities_red[Neuron_with_possible_artefact])\n",
    "plt.show()\n",
    "\n",
    "#After Correction:\n",
    "plt.figure(2)\n",
    "plt.plot(CaSignal[Neuron_with_possible_artefact])\n",
    "plt.title('Calcium Signal Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional Cell to Evaluate Activity and Tracking of Individual Neurons**     \n",
    "Allows comparison between intensity trace of a neuron and that neuron's ROI at a particular frame    \n",
    "Input Neuron Number and Frame Number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block #12: single neuron full evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input neuron to check\n",
    "neuron = 12\n",
    "\n",
    "#input frame form video to view the ROI\n",
    "eval_frame = 509\n",
    "\n",
    "full_eval(neuron, CaSignal, eval_frame, dim, posit_corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FILTERING & SMOOTHING\n",
    "-----------------------\n",
    "\n",
    "The following cells will filter the intensity traces of the neurons to remove signal that are likely from nematocytes, smooth the results to reduce the appearance of noise, and detrend the resulting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block #13: de-trending and filtering non-neuornal cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detrending data - use on filtered or smoothed data\n",
    "\n",
    "#Set Polynomial Degree\n",
    "poly_deg = 17\n",
    "\n",
    "detrended = detrend_all(CaSignal, poly_deg)\n",
    "\n",
    "temp1 = posit_corrected\n",
    "temp2 = detrended\n",
    "\n",
    "#posit_corrected = temp1\n",
    "#detrended = temp2\n",
    "\n",
    "#Filter Nematocytes\n",
    "\n",
    "#set the threshold to remove below\n",
    "#standard option is to set to 20 (i.e. filter will remove signals with below the 20th percentile of standard deviations)\n",
    "#percentile_threshold = 10 #zero = no filtering\n",
    "#filt, posit_corrected = filt_nematocytes(CaSignal,percentile_threshold,posit_corrected)\n",
    "alpha = 1e-6 #Tune threshold for coherence to gaussian distribution - need to use detrended data with this function\n",
    "detrended, posit_corrected, removed = Gaussian_noise_filter(detrended, alpha, posit_corrected)\n",
    "#evaluate filtering of neurons\n",
    "\n",
    "plot_all(removed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block #14 display de-trending and filtering results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display Filtering and Smoothing Results\n",
    "\n",
    "#Display Total Number of Neurons After Filtering\n",
    "print('no of neurons: ', len(detrended))\n",
    "\n",
    "plt.figure(3)\n",
    "for i in range(len(detrended)):\n",
    "    plt.plot(detrended[i])\n",
    "plt.title('Detrended Calcium Signal Data')\n",
    "plt.xlabel('Frame')\n",
    "plt.ylabel('Calcium Signal Detrended')\n",
    "plt.show()\n",
    "\n",
    "plot_heatmap(norm_all_data(detrended), 'Heatmap of Filtered Detrended Data', 'Calcium Signal Intensity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block #15: plot all de-trended neurons after filtering and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot all remaining neurons after filtering and processing\n",
    "plot_all(detrended)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CALCIUM SIGNAL ANALYSIS\n",
    "-------------------------------------\n",
    "\n",
    "The following cells analyse the results to show extract spikes from the Calcium intensity data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tune Threshold used to Indentify Spikes to Fit Data Using Evaluation Cell for FOOPSI at End of Script**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block #16 denoise and deconvolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Raster Plot using CAIMAN's FOOPSI function - Denoising and Deconvolution\n",
    "\n",
    "#foopsi\n",
    "Foopsi_ca, spikes_signal_dR = FOOPSI_all(detrended)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block #17 plot all denoised calcium traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot all denoised calcium traces\n",
    "plot_all(spikes_signal_dR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block #18 plot heatmap of all denoised signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(norm_all_data(Foopsi_ca), 'Denoised heatmap', 'Intensity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block #19 extract raster plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Raster Plot Data\n",
    "\n",
    "#Threshold (could use a theoretical value for threshold! - See CAIMAN Docs - but trial & error is also fine)\n",
    "#USE FOOPSI EVALUATION CELL TO TUNE THIS PARAMETER (0.04 works well)\n",
    "spike_thresh_dR = 0.1\n",
    "\n",
    "raster_array_dR = Find_Raster_adaptive(spikes_signal_dR, spike_thresh_dR)\n",
    "\n",
    "#Display Results\n",
    "\n",
    "#plot raster\n",
    "#zero values from way array was made array give large syncronous train at start of the signal - should fix (.append method?)\n",
    "plt.figure(2)\n",
    "plt.eventplot(raster_array_dR,linelengths = 0.6)\n",
    "plt.ylabel('Neuron')\n",
    "plt.xlabel('Frame')\n",
    "plt.title('Raster Plot of Neural Activity of Hydra')\n",
    "plt.xlim((1,len(raster_array_dR[0])))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block #20 display raster plot for all individual neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot rasterplot for all neurons\n",
    "for i in range(len(raster_array_dR)):\n",
    "    plt.eventplot(raster_array_dR[i],linelengths = 0.1)\n",
    "    plt.xlim((1,len(raster_array_dR[0])))\n",
    "    plt.title(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BEHAVIOUR ANALYSIS WITH NEURAL ACTIVITY\n",
    "---------------------------------------------\n",
    "These cells plot neural activity and behaviour together to allow comparision between neural activity and behaviour     \n",
    "Most of this step still needs to be done by hand unfortunately..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block #21 define behaviour arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input Behaviour Arrays\n",
    "\n",
    "#behaviour array: [frame behaviour turns on,frame off,on,off,on,... etc]\n",
    "behaviour_frames = []\n",
    "\n",
    "#fill with numbered behaviourws in order they occur (e.g. frame 0 to 150, 600 to 830, etc.)\n",
    "behaviours = []\n",
    "\n",
    "#fill with colours corresponding to numbered behaviours\n",
    "colours=['blue','green']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block #22 display neural activity with behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display Neural Activity with Behaviour\n",
    "\n",
    "plt.figure(1)\n",
    "fig, ax = plt.subplots()\n",
    "ax.margins(0.02)\n",
    "for behav in range(len(behaviour_frames)-1):\n",
    "    colour_face = colours[behaviours[behav]]\n",
    "    ax.axvspan(behaviour_frames[behav],behaviour_frames[behav+1], facecolor = colour_face, alpha = 0.2)\n",
    "for i in range(len(intensities)):\n",
    "    plt.plot(intensities[i])\n",
    "plt.title('Raw Intensities plotted with CB and RP behaviour (CB=green)')\n",
    "plt.xlabel('Frame')\n",
    "plt.ylabel('Intensity')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(2)\n",
    "fig, ax = plt.subplots()\n",
    "ax.margins(0.02)\n",
    "for behav in range(len(behaviour_frames)-1):\n",
    "    colour_face = colours[behaviours[behav]]\n",
    "    ax.axvspan(behaviour_frames[behav],behaviour_frames[behav+1], facecolor = colour_face, alpha = 0.2)\n",
    "for i in range(len(detrended)):\n",
    "    plt.plot(detrended[i])\n",
    "plt.title('Processed Intensities plotted with CB and RP behaviour (CB=green)')\n",
    "plt.xlabel('Frame')\n",
    "plt.ylabel('Calcium Signal Intensities Detrended')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(3)\n",
    "fig, ax = plt.subplots()\n",
    "ax.margins(0.02)\n",
    "for behav in range(len(behaviour_frames)-1):\n",
    "    colour_face = colours[behaviours[behav]]\n",
    "    ax.axvspan(behaviour_frames[behav],behaviour_frames[behav+1], facecolor = colour_face,alpha = 0.2)\n",
    "plt.eventplot(raster_array_dR,linelengths = 0.6)\n",
    "plt.xlim((1,len(raster_array_dR[0])))\n",
    "plt.ylabel('Neuron')\n",
    "plt.xlabel('Frame')\n",
    "plt.title('Raster Plot of Neural Activity of Hydra Plotted with Behaviour')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CORRELATION AND INTERPRETATION OF DATA\n",
    "-----------------------------------\n",
    "The following cells work to group neurons together into ensembles, display various froms of correlation data presentation, and correlate each neuron to different types of behaviour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input Correlation Threshold to be Used to Group Neurons**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block #23 create dendrogram of neural activity based on correlation distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Dendrogram (can change method between ward, average, etc)\n",
    "CaSignal_norm = spikes_signal_dR\n",
    "df = pd.DataFrame(np.transpose(CaSignal_norm))\n",
    "plt.figure(figsize=(20, 20))  \n",
    "plt.title(\"Dendrograms\")\n",
    "palette = ['g','r','c','m','y','chartreuse','burlywood','DeepPink','orange']\n",
    "shc.set_link_color_palette(palette)\n",
    "dend = shc.dendrogram(shc.linkage(df.corr(), method='ward'),leaf_font_size=10,color_threshold = 3.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block #24 summarize clustering information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cluster_info = get_cluster_classes(dend)\n",
    "get_cluster_classes(dend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block #25 re-order and color-code the raster plot of neural activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mylist = raster_array_dR\n",
    "myorder = dend['leaves']\n",
    "mylist = [mylist[i] for i in myorder]\n",
    "cluster_info = get_cluster_classes(dend)\n",
    "plt.figure(figsize=(30, 30))\n",
    "for col in set(dend['color_list']):\n",
    "    if col != 'b':\n",
    "        for row in cluster_info[col]:\n",
    "            plt.axhline(y=dend['leaves'].index(int(row)), color = col, alpha = 0.2, linewidth=5)\n",
    "\n",
    "for behav in range(len(behaviour_frames)-1):\n",
    "    colour_face = colours[behaviours[behav]]\n",
    "    plt.axvspan(behaviour_frames[behav],behaviour_frames[behav+1], facecolor = colour_face,alpha = 0.2)\n",
    "    \n",
    "plt.eventplot(mylist,linelengths = 0.4)\n",
    "plt.xlim((1,len(raster_array_dR[0])))\n",
    "plt.ylabel('Neuron')\n",
    "plt.xlabel('Frame')\n",
    "plt.title('Raster Plot of Neural Activity Sorted by Cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### **Input Number of Clusters Based on Results from Dendogram**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block #26 display cluster-specific neural traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#extract and view neurons from each cluster \n",
    "\n",
    "#number of clusters chosen from examination of dendogram\n",
    "#number_of_clusters = 7\n",
    "\n",
    "# use this function for Eucledian dendrograms\n",
    "#clusters = give_cluster_assigns(pd.DataFrame(np.transpose(CaSignal_norm)), number_of_clusters, transpose=True)\n",
    "#clusters = clusters.values\n",
    "\n",
    "\n",
    "# Use this instead for Correlation dendrograms\n",
    "\n",
    "# manually set the colors from the dendrogram\n",
    "cluster_colors = palette\n",
    "\n",
    "clusters = np.zeros((len(raster_array_dR),), dtype=int)\n",
    "number_of_clusters = 0\n",
    "for col in set(dend['color_list']):\n",
    "    if col != 'b':\n",
    "        number_of_clusters += 1\n",
    "        for row in cluster_info[col]:\n",
    "            clusters[int(row)] = cluster_colors.index(col)+1\n",
    "   \n",
    "                     \n",
    "#plot specific cluster's neurons traces\n",
    "\n",
    "cluster_to_view = 0\n",
    "average_intensities = np.zeros(number_of_clusters)\n",
    "cluster_sizes = np.zeros(number_of_clusters)\n",
    "\n",
    "for i in range(len(clusters)):\n",
    "    average_intensities[clusters[i]-1] += np.sum(Foopsi_ca[i])/len(vid)\n",
    "    cluster_sizes[clusters[i]-1] += 1\n",
    "    if clusters[i] == cluster_to_view:\n",
    "        plt.figure(i-1)\n",
    "        plt.title(i)\n",
    "        plt.eventplot(raster_array_dR[i])\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "average_intensities = average_intensities/cluster_sizes\n",
    "plt.bar(range(1,number_of_clusters+1),average_intensities)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block #27 create correlation heatmap for all neural signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ClusterMap\n",
    "#change figure size to see all labels if necessary\n",
    "\n",
    "df = pd.DataFrame(np.transpose(CaSignal_norm))\n",
    "\n",
    "# Draw the full plot\n",
    "sns.clustermap(df.corr(), center=0, cmap=\"coolwarm\",linewidths=.75, figsize=(20,20), method = 'ward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block #28 super-impose color-coded ensembles on input videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Super impose locations of neurons in specified Cluster onto video frame\n",
    "\n",
    "os.chdir('C:\\\\Users\\\\rylab\\\\Desktop\\\\AliA\\\\Best 10X\\\\')\n",
    "cwd = os.getcwd()\n",
    "#os.mkdir('test')\n",
    "os.chdir('test')\n",
    "\n",
    "color_codes = ['']*len(raster_array_dR)\n",
    "for i in range(len(color_codes)):\n",
    "    for color,track in cluster_info.items():\n",
    "        temp = str(i)\n",
    "        if temp in track:\n",
    "            color_codes[i] = str(color)\n",
    "                \n",
    "cluster_to_view = [1,2,3,4,5,6,7,8,9]\n",
    "frame_for_cluster = 0\n",
    "number_of_frames = len(vid)\n",
    "video_for_cluster = red_vid\n",
    "title_for_cluster = 'Cluster Positions'\n",
    "\n",
    "Super_impose_cluster(video = video_for_cluster, frame_to_view = frame_for_cluster, \\\n",
    "                     posit_corrected = posit_corrected, clusters = clusters, cluster_to_view = cluster_to_view, \\\n",
    "                     Title = title_for_cluster, sequence = number_of_frames, color_codes = color_codes)\n",
    "\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Investigate Correlations from ClusterMap\n",
    "\n",
    "#input neurons to view\n",
    "neuron_1 = 71\n",
    "neuron_2 = 36\n",
    "\n",
    "plt.figure(1)\n",
    "fig, ax = plt.subplots()\n",
    "ax.margins(0.02)\n",
    "for behav in range(len(behaviour_frames)-1):\n",
    "    colour_face = colours[behaviours[behav]]\n",
    "    ax.axvspan(behaviour_frames[behav],behaviour_frames[behav+1], facecolor = colour_face,alpha = 0.2)\n",
    "plt.plot(detrended[neuron_1])\n",
    "plt.plot(detrended[neuron_2])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(2)\n",
    "plt.title(neuron_1)\n",
    "plt.eventplot(raster_array_dR[neuron_1],linelengths = 0.6)\n",
    "plt.xlim((1,len(raster_array_dR[0])))\n",
    "plt.show()\n",
    "\n",
    "plt.figure(3)\n",
    "plt.title(neuron_2)\n",
    "plt.eventplot(raster_array_dR[neuron_2],linelengths = 0.6)\n",
    "plt.xlim((1,len(raster_array_dR[0])))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Single neuron investigation\n",
    "\n",
    "neuron_to_investigate = 50\n",
    "frame_to_investigate = 1606\n",
    "\n",
    "single_neuron_investigation(neuron_to_investigate, CaSignal, vid, frame_to_investigate, dim, posit_corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Data**\n",
    "===============\n",
    "**Optional Cells to Save Results**        \n",
    "Run these cells to save the data as a .csv         \n",
    "Input file name and path where file should be saved           \n",
    "**On Windows: Paths still need to start with 'r'**              \n",
    "e.g. r'C:\\Users\\rylab\\Documents\\path to your folder\\title.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Raw GCamp Intensity Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Raw GCamp Intensity data as a .csv \n",
    "\n",
    "# Save_Path = r'C:\\Users\\rylab\\Documents\\Noah2019_desktop\\Columbia_Project\\hydra_Vids\\2-colour\\single_cell_intensity_behaviour_longclip.csv'\n",
    "\n",
    "# intensity_dataframe = pd.DataFrame(intensities)\n",
    "# intensity_dataframe.to_csv(Save_Path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save CaSignal Intensity Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save CaSignal data to .csv\n",
    "\n",
    "# Ca_save_path = r'C:\\Users\\rylab\\Documents\\Noah2019_desktop\\Columbia_Project\\hydra_Vids\\2-colour\\single_cell_CaSig.csv'\n",
    "\n",
    "# intensity_dataframe = pd.DataFrame(CaSignal)\n",
    "# intensity_dataframe.to_csv(Ca_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sava Detrended Intensity Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save detrended data to .csv\n",
    "\n",
    "# dR_detrend_save_path = r'C:\\Users\\rylab\\Documents\\Noah2019_desktop\\Columbia_Project\\hydra_Vids\\2-colour\\single_cell_detrend.csv'\n",
    "\n",
    "# dfintensity_dataframe = pd.DataFrame(detrended)\n",
    "# dfintensity_dataframe.to_csv(dR_detrend_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Foopsi De-noised Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #save Foopsi de-noised data to .csv\n",
    "\n",
    "# Ca_denoised_path = r'C:\\Users\\rylab\\Documents\\Noah2019_desktop\\Columbia_Project\\Project_Behaviour_and_Neural_Activity\\Single_Cell_Analysis_Neural\\Single_Cell_Data\\VID1_oct_4_3hz\\Results\\denoised_neuraldata.csv'\n",
    "\n",
    "# ca_dataframe = pd.DataFrame(Foopsi_ca)\n",
    "# ca_dataframe.to_csv(Ca_denoised_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Raster Plot Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save raster data to .csv (needs to be reformatted from event plot form first)\n",
    "\n",
    "# raster_save_path = r'C:\\Users\\rylab\\Documents\\Noah2019_desktop\\Columbia_Project\\hydra_Vids\\2-colour\\single_cell_rasterb1.csv'\n",
    "\n",
    "# raster_array_pred = np.zeros((len(raster_array_dR),len(raster_array_dR[1])))\n",
    "# for i in range(len(spikes_signal_dR)):\n",
    "#     for j in range(len(spikes_signal_dR[i])):\n",
    "#         if max(spikes_signal_dR[i]) > 0:\n",
    "#             if spikes_signal_dR[i][j] >= spike_thresh_dR: #*np.mean(spikes_signal_dR[i]):\n",
    "#                 raster_array_pred[i][j] = 1\n",
    "\n",
    "# raster_dataframe = pd.DataFrame(raster_array_pred)\n",
    "# raster_dataframe.to_csv(raster_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Behaviour Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Behaviour Array tp .csv\n",
    "# behaviour_Save_Path = r\"C:\\Users\\rylab\\Downloads\\behav_array.csv\"\n",
    "\n",
    "# behav_array = np.zeros(len(vid))\n",
    "# for i in range(len(behaviours)):\n",
    "#     behav_array[behaviour_frames[i]:behaviour_frames[i+1]] = behaviours[i]\n",
    "    \n",
    "# behaviour_dataframe = pd.DataFrame(behav_array)\n",
    "# behaviour_dataframe.to_csv(behaviour_Save_Path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation Cells**\n",
    "====================\n",
    "These cells allow for the evaluation of the tuning of various functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate Polynomial Detrending Parameters** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate ploynomail detrending\n",
    "neuron_test_detrend = 10\n",
    "#polynomial degree of 15-17 gives good results - but tune for new data!\n",
    "polynomial_test_degree  = 12\n",
    "detrend_one = detrend(smooth_intensities[neuron_test_detrend],polynomial_test_degree)\n",
    "plt.figure(1)\n",
    "plt.plot(detrend_one, c='b')\n",
    "plt.plot(smooth_intensities[neuron_test_detrend], c = 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluste ICA vs Ratiometric Artefact Removal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New ICA vs Ratiometric\n",
    "\n",
    "a, b = np.asanyarray(norm_Data(intensities[12])), np.asanyarray(norm_Data(intensities_red[12]))\n",
    "plt.plot(a, c = 'g')\n",
    "plt.title('Raw Intensities of GCaMP7 (Green) Channel')\n",
    "plt.xlabel('Frames')\n",
    "plt.ylabel('Normalised Intensity')\n",
    "plt.show()\n",
    "plt.plot(b, c = 'r')\n",
    "plt.title('Raw Intensities of tdTomato (Red) Channel')\n",
    "plt.xlabel('Frames')\n",
    "plt.ylabel('Normalised Intensity')\n",
    "plt.show()\n",
    "\n",
    "c = (a+1)/(b+1)\n",
    "plt.plot(c)\n",
    "plt.title('Ratiometric Correction of Motion Artefacts')\n",
    "plt.xlabel('Frames')\n",
    "plt.ylabel('Intensity Ratio')\n",
    "plt.show()\n",
    "\n",
    "print(min(a))\n",
    "print(min(b))\n",
    "\n",
    "ica_g = ICAdecorr([a],[b],0.05, 10)\n",
    "plt.plot(ica_g[0])\n",
    "plt.title('ICA Correction of Motion Artefacts')\n",
    "plt.xlabel('Frames')\n",
    "plt.ylabel('Normalised Intensity')\n",
    "# plt.show()\n",
    "# plot_all(p)\n",
    "# print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate FOOPSI Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuning for FOOPSI \n",
    "\n",
    "tuning_thresh_foopsi = 0.001\n",
    "\n",
    "evaluation_neuron_foopsi = 10\n",
    "spikes_signal_tuning = FOOPSI_all(normalize(detrended))\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(detrended[evaluation_neuron_foopsi])\n",
    "plt.title('detrended signal for Specified Neuron')\n",
    "plt.ylabel('Calcium Signal Detrended Intensity')\n",
    "plt.xlabel('Frame Number')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(spikes_signal_dR[evaluation_neuron_foopsi])\n",
    "plt.title('FOOPSI Results for Specified Neuron')\n",
    "plt.ylabel('Estimated Neural Activity')\n",
    "plt.xlabel('Frame Number')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate use of ICA or DeltaR/R to separate signal from noise**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ICA artifact removal comparison cell\n",
    "ICA_test_neuron = 9\n",
    "R = intensities_red\n",
    "G = intensities\n",
    "\n",
    "a = decorrelateNeuronsICA(R, G, 0.2)\n",
    "\n",
    "plt.plot(G[ICA_test_neuron], c = 'g')\n",
    "plt.plot(R[ICA_test_neuron], c = 'r')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(a[ICA_test_neuron], c = 'g')\n",
    "plt.title('ICA')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(deltaR[ICA_test_neuron], c = 'r')\n",
    "plt.title('DR/R')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find Raster Plot from Non-DR/R data**    \n",
    "Recalculates the spikes from the raw data and plots the results      \n",
    "Evaluates best input to use with FOOPSI Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raster with non-dR/R - Compare Rasters from different input data\n",
    "\n",
    "Raw_filt, _ = np.asanyarray(filt_nematocytes(intensities, 5, positions))\n",
    "\n",
    "raw_smooth = smoother(Raw_filt, 5)\n",
    "\n",
    "df_f_signal = np.asanyarray(df_f(raw_smooth))\n",
    "\n",
    "\n",
    "plt.figure(1)\n",
    "for i in range(len(raw_smooth)):\n",
    "    plt.plot(raw_smooth[i])\n",
    "plt.title('Intensity Plot Raw smooth')\n",
    "plt.xlabel('Frame')\n",
    "plt.ylabel('Intensity')\n",
    "plt.show()\n",
    "\n",
    "#Create Raster Plot using CAIMAN's FOOPSI function\n",
    "#foopsi (used on non-df/f data)\n",
    "spikes_signal = np.zeros((len(Raw_filt),len(Raw_filt[1])))\n",
    "for i in range(len(Raw_filt)):\n",
    "    ca_foopsi,cb,b1,g,c1,spikes_foopsi,lam = deconv.constrained_foopsi(Raw_filt[i],p=2)\n",
    "    spikes_signal[i] = spikes_foopsi\n",
    "    \n",
    "#foopsi (used on df/f data)\n",
    "spikes_signal_df = np.zeros((len(df_f_signal),len(df_f_signal[1])))\n",
    "for i in range(len(df_f_signal)):\n",
    "    ca_foopsi,cb,b1,g,c1,spikes_foopsi,lam = deconv.constrained_foopsi(df_f_signal[i],p=2)\n",
    "    spikes_signal_df[i] = spikes_foopsi\n",
    "\n",
    "#threshold to find spikes\n",
    "spike_thresh = 0.3\n",
    "\n",
    "raster_array = np.zeros((len(Raw_filt),len(Raw_filt[1])))\n",
    "for i in range(len(spikes_signal)):\n",
    "    for j in range(len(spikes_signal[i])):\n",
    "        if spikes_signal[i][j] >= spike_thresh*max(spikes_signal[i]):\n",
    "            raster_array[i][j] = j\n",
    "\n",
    "raster_array_df = np.zeros((len(df_f_signal),len(df_f_signal[1])))\n",
    "for i in range(len(spikes_signal_df)):\n",
    "    for j in range(len(spikes_signal_df[i])):\n",
    "        if spikes_signal_df[i][j] >= spike_thresh*max(spikes_signal_df[i]):\n",
    "            raster_array_df[i][j] = j\n",
    "\n",
    "#Plot raster for base data\n",
    "#zero values from way array was made array give large syncronous train at start of the signal - should fix (.append method?)\n",
    "plt.figure(3)\n",
    "plt.eventplot(raster_array,linelengths = 0.5)\n",
    "plt.title('Raster Plot of All Neurons (raw intensities)')\n",
    "plt.xlabel('Frame Number')\n",
    "plt.ylabel('Neuron')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(4)\n",
    "plt.eventplot(raster_array_df,linelengths = 0.5)\n",
    "plt.title('Raster Plot of All Neurons (df/f intensities)')\n",
    "plt.xlabel('Frame Number')\n",
    "plt.ylabel('Neuron')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternative Clustering Visualisation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clustering Data - evaluate clustering with a cluster map (provides some extra visualisation if you want it but I prefer other methods)\n",
    "#Input Number of Clusters Based on Results from Dendogram\n",
    "\n",
    "eucdist = cdist(CaSignal_norm,CaSignal_norm)\n",
    "cluster = AgglomerativeClustering(n_clusters=number_of_clusters, affinity='euclidean')\n",
    "cluster.fit_predict(CaSignal_norm)\n",
    "plt.figure(figsize=(10, 7))  \n",
    "plt.scatter(eucdist[:,1], eucdist[:,0],c=cluster.labels_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate Raster Reshaping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Evaluate Raster Reshaping step for saving as csv\n",
    "\n",
    "# raster_reshape_test_neuron = 5\n",
    "\n",
    "# plt.plot(raster_array_pred[raster_reshape_test_neuron], color = 'r')\n",
    "# plt.eventplot(raster_array_dR[raster_reshape_test_neuron])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate Neuron Tracking**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 57\n",
    "_,_,_,display = SingleCellIntensity(neuron = n, video = vid, positions = posit_corrected, dimentionROI = dim, Circle_radius = 4, distance_threshold = 4, display_on = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Tracked Neurons**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(display)):\n",
    "#     plt.imshow(display[i])\n",
    "#     title = 'neuron_' + str(i) + '.tif'\n",
    "#     plt.savefig(str(title), format = 'tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimental Cells\n",
    "==============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raster using peak detection function - needs tuning...\n",
    "\n",
    "neuron_for_peaks = 50\n",
    "distance_between_peaks = 10\n",
    "prominance_of_peaks = 0.05\n",
    "\n",
    "a,b = sp.signal.find_peaks(detrended[neuron_for_peaks], distance = distance_between_peaks, prominence = prominance_of_peaks)\n",
    "plt.figure(1)\n",
    "plt.plot(detrended[neuron_for_peaks])\n",
    "plt.plot(a, detrended[neuron_for_peaks][a], 'x')\n",
    "plt.show()\n",
    "\n",
    "raster2 = np.zeros((len(detrended), len(detrended[1])))\n",
    "for i in range(len(detrended)):\n",
    "    peaks,_ = sp.signal.find_peaks(detrended[i], distance = distance_between_peaks, prominence = prominance_of_peaks)\n",
    "    for j in range(len(detrended[i])):\n",
    "        for k in range(len(peaks)):\n",
    "            raster2[i][peaks[k]] = 1\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(raster2[neuron_for_peaks])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#frequency filtering\n",
    "#sampling rate = 3Hz\n",
    "#hmm doesnt seem to work well at all\n",
    "\n",
    "neurons = 10\n",
    "\n",
    "frqs = np.fft.fft(detrended[neuron])\n",
    "xax = np.arange(0,6000, 6000/(len(detrended[0])))\n",
    "plt.figure(1)\n",
    "plt.title('Fourier Spectrum')\n",
    "plt.plot(abs(frqs.real))\n",
    "\n",
    "\n",
    "#freqs adjusted\n",
    "filter_block = np.ones(len(detrended[0]))\n",
    "low_pass_cut = 30\n",
    "filter_block[low_pass_cut:len(filter_block)-low_pass_cut] = 0\n",
    "#filter_block[len(filter_block) - 80: len(filter_block) - 55] = 1\n",
    "plt.plot(filter_block)\n",
    "plt.show()\n",
    "new_freqs = np.fft.ifft(frqs*filter_block)\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(new_freqs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #independant component analysis to separate noise - single neuron\n",
    "\n",
    "# ica_test_neuron = 9\n",
    "# window = 5\n",
    "\n",
    "# data_green = [intensities[ica_test_neuron]]\n",
    "# filtered_data_g = smoother(data_green,window)\n",
    "# filtered_data_g = np.transpose(detrend(np.transpose(filtered_data_g), 17))\n",
    "# plt.figure(1)\n",
    "# plt.plot(filtered_data_g[0],c='g')\n",
    "# # plt.plot(data_green[0],'r')\n",
    "\n",
    "# data_red = [intensities_red[ica_test_neuron]]\n",
    "# filtered_data_r = smoother(data_red,window)\n",
    "# filtered_data_r = np.transpose(detrend(np.transpose(filtered_data_r), 17))\n",
    "# plt.figure(2)\n",
    "# plt.plot(filtered_data_r[0],c='r')\n",
    "# # plt.plot(data_red[0],'r')\n",
    "# plt.show()\n",
    "\n",
    "# X = np.c_[filtered_data_g[0],filtered_data_r[0]]\n",
    "# print(X.shape)\n",
    "# X = X.reshape(len(filtered_data_g[0]),2)\n",
    "# print(X.shape)\n",
    "# # scaler= StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "# # X = scaler.fit_transform(X)\n",
    "# ica = FastICA(n_components = 2, random_state = None)\n",
    "# A = ica.fit_transform(X)\n",
    "\n",
    "# plt.figure(3)\n",
    "# plt.plot(X[:,0], c='g')\n",
    "# plt.plot(X[:,1], c='r')\n",
    "# plt.plot(data_green, c='b')\n",
    "# plt.plot(data_red, c='y')\n",
    "# plt.figure(4)\n",
    "# plt.plot(A[:,0])\n",
    "# plt.plot(A[:,1])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Correlation Between Neural Activity and Behaviour\n",
    "# #Method finds change in neural activity between CB and RP\n",
    "\n",
    "# #select neuron to observe\n",
    "# neuron = 44\n",
    "\n",
    "# #select lenght of sub sequences (will depend on number of frames behaviour takes up)\n",
    "# seqlen = 100\n",
    "\n",
    "# df_on = smooth_intensities[neuron][301:565] + smooth_intensities[neuron][991:1076]\n",
    "# df_ons = []\n",
    "# for i in range(int(len(df_on)/seqlen)):\n",
    "#     df_ons.append(df_on[i*seqlen:(i*seqlen)+seqlen])\n",
    "\n",
    "# df_off = smooth_intensities[neuron][0:301] + smooth_intensities[neuron][565:991] + smooth_intensities[neuron][1076: len(smooth_intensities[0])]\n",
    "# df_offs = []\n",
    "# for i in range(int(len(df_off)/seqlen)):\n",
    "#     df_offs.append(df_off[i*seqlen:(i*seqlen)+seqlen])\n",
    "    \n",
    "# #find average of on signal\n",
    "# avg_on = []\n",
    "# for i in range(len(df_ons[0])):\n",
    "#     values = []\n",
    "#     for j in range(len(df_ons)):\n",
    "#         values.append(df_ons[j][i]) \n",
    "#     avg_on.append(np.mean(values))\n",
    "\n",
    "# #find average of off signal\n",
    "# avg_off = []\n",
    "# for i in range(len(df_offs[0])):\n",
    "#     values = []\n",
    "#     for j in range(len(df_offs)):\n",
    "#         values.append(df_offs[j][i]) \n",
    "#     avg_off.append(np.mean(values))\n",
    "\n",
    "# #correlation\n",
    "# corr_on_off = np.corrcoef(avg_off,avg_on)[0,1]\n",
    "# print('Pearson Correlation Coeff: ', corr_on_off)\n",
    "\n",
    "# #if correlation is very low, neurons change activity patterns during behaviour!!\n",
    "# if abs(corr_on_off) < 0.5:\n",
    "#     print('Neuron Changes Activity During Behaviour')\n",
    "# else:\n",
    "#     print('Neuron Does Not Change Activity During Behaviour')\n",
    "    \n",
    "# plt.plot(avg_on)\n",
    "# plt.plot(avg_off)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
