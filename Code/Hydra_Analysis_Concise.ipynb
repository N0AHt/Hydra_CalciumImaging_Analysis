{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Single Cell Resolution Analysis of Ca Imaging Data for Hydra** \n",
    "=============================================================\n",
    "*(Use with data from tdTomato_GCamP Animals)*\n",
    "\n",
    "Requires:\n",
    "-------------------------\n",
    "- Green and Red Channel Videos From 2-Colour Confocal (GCaMP Channel and tdTomato)\n",
    "- Tracking Position Information From ICY Spot Tracking Protocol (Exported as CSV)\n",
    "- Conda Environment: Caiman_NOAH3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INPUT PATHS\n",
    "-----------------\n",
    "Enter paths to the appropriate files                    \n",
    "**Videos must be .avi (convert in imageJ if not)**     \n",
    "**Can also use a Tif sequence folder - change the read data function to Read_Data_TIFseq for this**    \n",
    "**If using windows**: Paths must start with an 'r' character: e.g. vid_path = **r**\"C:\\Users\\rylab\\ path to your file \\clip.avi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input path to your .csv from ICY\n",
    "csv_path = r\"C:\\Users\\gabte\\Documents\\Hydra_CalciumImaging_Analysis\\Example_Data\\AVIs_and_CSV\\points.csv\"\n",
    "\n",
    "#input path to .avi of GCaMP Video\n",
    "vid_path = r\"C:\\Users\\gabte\\Documents\\Hydra_CalciumImaging_Analysis\\Example_Data\\AVIs_and_CSV\\green(1-852).avi\"\n",
    "\n",
    "#input path to .avi of tdTomato Video\n",
    "red_vid_path = r\"C:\\Users\\gabte\\Documents\\Hydra_CalciumImaging_Analysis\\Example_Data\\AVIs_and_CSV\\red(1-852).avi\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SET UP DATA  \n",
    "-----------------------\n",
    "Run the following cells to set up the \n",
    "data to be analysed        \n",
    "**Set the FFmpeg path before running this cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing packages for hydra analysis (from same directory)\n",
    "\n",
    "import skvideo\n",
    "#set this path to the FFmpegTool\\bin location on your machine (download FFmpeg if not already installed)\n",
    "#make sure to restart the kernel after setting the path\n",
    "skvideo.setFFmpegPath(r\"C:\\Users\\gabte\\Downloads\\ffmpeg-20200615-9d80f3e-win64-static\\bin\")\n",
    "\n",
    "import SingleCellHydraAnalysis as hy\n",
    "\n",
    "# import os\n",
    "# import numpy as np\n",
    "# import scipy as sp\n",
    "# import skimage.io as iio\n",
    "# import skvideo\n",
    "# from io import BytesIO\n",
    "# from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "# import skvideo.io as io\n",
    "# import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# from caiman.source_extraction.cnmf import deconvolution as deconv\n",
    "# from scipy.spatial.distance import cdist, pdist, euclidean\n",
    "# from sklearn.preprocessing import normalize\n",
    "# from sklearn.decomposition import FastICA\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# import scipy.cluster.hierarchy as shc\n",
    "# from sklearn.cluster import AgglomerativeClustering\n",
    "# import seaborn as sns\n",
    "# import cv2\n",
    "\n",
    "# from collections import defaultdict\n",
    "# from scipy.cluster.hierarchy import dendrogram, set_link_color_palette\n",
    "# import seaborn as sns\n",
    "# from matplotlib.colors import rgb2hex, colorConverter\n",
    "# from tqdm import tqdm\n",
    "# from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in data\n",
    "positions, vid, red_vid = hy.Read_Data(csv_path, vid_path, red_vid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numer of Frames in Green Video: 852\n",
      "Number of Frames in Red Video: 852\n",
      "Number of Points Tracked by ICY: 713\n"
     ]
    }
   ],
   "source": [
    "#Get Information About Raw Data\n",
    "num_frames = len(vid)\n",
    "num_red_frames = len(red_vid)\n",
    "num_tracks = int(positions[-1,0])\n",
    "#Display Information\n",
    "print('Numer of Frames in Green Video:', num_frames)\n",
    "print('Number of Frames in Red Video:', num_red_frames)\n",
    "print('Number of Points Tracked by ICY:', num_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "164.0 [652]\n"
     ]
    }
   ],
   "source": [
    "window_size = 200\n",
    "max_tracked, max_index = hy.rapid_reshaper_MW(positions, num_frames, window_size)\n",
    "max_index = max_index[-1]\n",
    "print(max_tracked, max_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = vid[max_index[0]:]\n",
    "red_vid = red_vid[max_index[0]:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of fully tracked neurons:  118\n"
     ]
    }
   ],
   "source": [
    "max_index = 500\n",
    "posit_corrected = hy.rapid_reshaper(positions, num_frames, start = max_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CALCIUM SIGNAL EXTRACTION\n",
    "------------------------\n",
    "These following cells will remove neurons that were not completely tracked throughout the video, extract a region of interest around each fully tracked neuron, and extract the intensity of each neuron throughout the video and plot the raw intensities. The signal can then be corrected for motion artefacts by finding the ratiometric signal between the green and red channels - dR/R; or through the use of Independant Component Analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Following 2 Cells may Give a Runtime Warning - This is Fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:00<00:00, 540.26it/s]\n"
     ]
    }
   ],
   "source": [
    "#Extract the fluorescence intensity in the GCaMP channel throughout the video for each neuron\n",
    "\n",
    "#posit_corrected = np.delete(posit_corrected,[146],0)\n",
    "# posit_corrected = np.delete(posit_corrected,[148],0)\n",
    "# posit_corrected = np.delete(posit_corrected,[172],0)\n",
    "# posit_corrected = np.delete(posit_corrected,[172],0)\n",
    "# posit_corrected = np.delete(posit_corrected,[177],0)\n",
    "# posit_corrected = np.delete(posit_corrected,[178],0)\n",
    "# posit_corrected = np.delete(posit_corrected,[183],0)\n",
    "\n",
    "#size of ROI\n",
    "dim = 4\n",
    "intensities, posit_corrected = hy.Extract_Fluorescence_corrected(posit_corrected, vid, dimention = dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "#del posit_corrected[70]\n",
    "\n",
    "intensities, posit_corrected, neuron_pts = hy.SingleCellIntensities_corrected(vid, posit_corrected, dim, 4, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Must Run the Extract_Fluorescence function before the SingleCellIntensities function as you need to use the updated 'posit_corrected' output from Extract_Fluorescence as SingleCellIntensities as no feature to correct this itself**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "#Extract the fluorescence intensity in the Red channel throughout the video for each neuron\n",
    "\n",
    "intensities_red, posit_corrected = hy.Extract_Fluorescence(posit_corrected, red_vid, dim)\n",
    "\n",
    "#intensities_red = SingleCellIntensities_Red(red_vid, neuron_pts, posit_corrected, dim, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of neurons =  0\n"
     ]
    }
   ],
   "source": [
    "#plot raw neuronal intensities & display number of fully tracked neurons\n",
    "number_of_neurons = len(intensities)\n",
    "print('number of neurons = ', number_of_neurons)\n",
    "\n",
    "for track in range(len(intensities)):\n",
    "    plt.plot(intensities[track])\n",
    "    plt.title('Raw GCaMP Intensity plots of all sufficiently recorded neurons')\n",
    "    plt.xlabel('Frame')\n",
    "    plt.ylabel('Intenstiy')\n",
    "plt.show()\n",
    "\n",
    "#Plot intensities of red channels - used to identify motion artefacts and leaking between channels\n",
    "for track in range(len(intensities)):\n",
    "    plt.plot(intensities_red[track])\n",
    "    plt.title('Intensity Plot of Red Channel')\n",
    "    plt.xlabel('Frame')\n",
    "    plt.ylabel('Neuron')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#DeltaR/R or ICA used to correct for motion artefacts and cross channel leaking\n",
    "#Obtain Artefact Free Ca Signal\n",
    "CaSignal = hy.ICAdecorr(intensities, intensities_red, 0.5, 10)\n",
    "\n",
    "#Plot Signal\n",
    "for i in range(len(CaSignal)):\n",
    "    plt.plot(CaSignal[i])\n",
    "plt.title('Extracted Calcium Signal Plot')\n",
    "plt.xlabel('Frame')\n",
    "plt.ylabel('Ca Intensity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Heatmap of Calcium Signal\n",
    "#can normalise here for better signal...\n",
    "plot_heatmap(CaSignal, 'Heatmap of Extracted Calcium Signal', 'Ca Signal Intensity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcium Signal Extraction - Optional Cells\n",
    "--------------------------\n",
    "**These Cells Dont Need to be Run**          \n",
    "Cells for evaluating performance or saving preliminary results        \n",
    "Only Run the Cells you want to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional Cells to Evaluate ROI Tracking**      \n",
    "Input frame number to view all of the ROIs tracked in that frame      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#superimpose ROIs on video frame in both channels\n",
    "\n",
    "#select frame to view\n",
    "frame_to_view = 1606\n",
    "\n",
    "Super_impose(vid, frame_to_view, 'Neuron Tracking in Green Channel')\n",
    "Super_impose(red_vid, frame_to_view, 'Neuron Tracking in Red Channel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional Cells to Evaluate Effect and Correction of Motion Artifacts and Red Leakage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Raw Transients in Green\n",
    "plot_all(intensities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Red Transient to check for motion artefacts and leaking\n",
    "Neuron_with_possible_artefact = 11\n",
    "\n",
    "plt.figure(1)\n",
    "plt.title('Raw Red Channel Plot')\n",
    "plt.plot(intensities_red[Neuron_with_possible_artefact])\n",
    "plt.show()\n",
    "\n",
    "#After Correction:\n",
    "plt.figure(2)\n",
    "plt.plot(CaSignal[Neuron_with_possible_artefact])\n",
    "plt.title('Calcium Signal Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional Cell to Evaluate Activity and Tracking of Individual Neurons**     \n",
    "Allows comparison between intensity trace of a neuron and that neuron's ROI at a particular frame    \n",
    "Input Neuron Number and Frame Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input neuron to check\n",
    "neuron = 12\n",
    "\n",
    "#input frame form video to view the ROI\n",
    "eval_frame = 509\n",
    "\n",
    "full_eval(neuron, CaSignal, eval_frame, dim, posit_corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FILTERING & SMOOTHING\n",
    "-----------------------\n",
    "\n",
    "The following cells will filter the intensity traces of the neurons to remove signal that are likely from nematocytes, smooth the results to reduce the appearance of noise, and detrend the resulting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detrending data - use on filtered or smoothed data\n",
    "\n",
    "#Set Polynomial Degree\n",
    "poly_deg = 17\n",
    "\n",
    "detrended = detrend_all(CaSignal, poly_deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = posit_corrected\n",
    "temp2 = detrended\n",
    "\n",
    "#posit_corrected = temp1\n",
    "#detrended = temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Filter Nematocytes\n",
    "\n",
    "#set the threshold to remove below\n",
    "#standard option is to set to 20 (i.e. filter will remove signals with below the 20th percentile of standard deviations)\n",
    "#percentile_threshold = 10 #zero = no filtering\n",
    "#filt, posit_corrected = filt_nematocytes(CaSignal,percentile_threshold,posit_corrected)\n",
    "alpha = 1e-6 #Tune threshold for coherence to gaussian distribution - need to use detrended data with this function\n",
    "detrended, posit_corrected, removed = Gaussian_noise_filter(detrended, alpha, posit_corrected)\n",
    "#evaluate filtering of neurons\n",
    "\n",
    "plot_all(removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Smooth Signals\n",
    "\n",
    "# #Set Smoothing window Size\n",
    "#window = 2\n",
    "\n",
    "#smooth_intensities = smoother(filt, window)\n",
    "#detrended = smooth_intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display Filtering and Smoothing Results\n",
    "\n",
    "#Display Total Number of Neurons After Filtering\n",
    "print('no of neurons: ', len(detrended))\n",
    "\n",
    "# plt.figure(1)\n",
    "# for i in range(len(filt)):\n",
    "#     plt.plot(filt[i])\n",
    "# plt.title('Calcium Signal with Nematocytes Filtered')\n",
    "# plt.xlabel('Frame')\n",
    "# plt.ylabel('Calcium Signal')\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(2)\n",
    "# for i in range(len(smooth_intensities)):\n",
    "#     plt.plot(smooth_intensities[i])\n",
    "# plt.title('Smoothed Filtered Fluorescence with Single Neuron Resolution')\n",
    "# plt.xlabel('Frame')\n",
    "# plt.ylabel('Calcium Signal')\n",
    "# plt.show()\n",
    "\n",
    "plt.figure(3)\n",
    "for i in range(len(detrended)):\n",
    "    plt.plot(detrended[i])\n",
    "plt.title('Detrended Calcium Signal Data')\n",
    "plt.xlabel('Frame')\n",
    "plt.ylabel('Calcium Signal Detrended')\n",
    "plt.show()\n",
    "\n",
    "plot_heatmap(norm_all_data(detrended), 'Heatmap of Filtered Detrended Data', 'Calcium Signal Intensity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot all remaining neurons after filtering and processing\n",
    "plot_all(detrended)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CALCIUM SIGNAL ANALYSIS\n",
    "-------------------------------------\n",
    "\n",
    "The following cells analyse the results to show extract spikes from the Calcium intensity data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tune Threshold used to Indentify Spikes to Fit Data Using Evaluation Cell for FOOPSI at End of Script**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Raster Plot using CAIMAN's FOOPSI function - Denoising and Deconvolution\n",
    "\n",
    "#foopsi\n",
    "Foopsi_ca, spikes_signal_dR = FOOPSI_all(detrended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot all denoised calcium traces\n",
    "plot_all(spikes_signal_dR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Raster Plot Data\n",
    "\n",
    "#Threshold (could use a theoretical value for threshold! - See CAIMAN Docs - but trial & error is also fine)\n",
    "#USE FOOPSI EVALUATION CELL TO TUNE THIS PARAMETER (0.04 works well)\n",
    "spike_thresh_dR = 0.1\n",
    "\n",
    "raster_array_dR = Find_Raster_adaptive(spikes_signal_dR, spike_thresh_dR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(norm_all_data(Foopsi_ca), 'Denoised heatmap', 'Intensity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display Results\n",
    "\n",
    "#plot raster\n",
    "#zero values from way array was made array give large syncronous train at start of the signal - should fix (.append method?)\n",
    "plt.figure(2)\n",
    "plt.eventplot(raster_array_dR,linelengths = 0.6)\n",
    "plt.ylabel('Neuron')\n",
    "plt.xlabel('Frame')\n",
    "plt.title('Raster Plot of Neural Activity of Hydra')\n",
    "plt.xlim((1,len(raster_array_dR[0])))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot rasterplot for all neurons\n",
    "for i in range(len(raster_array_dR)):\n",
    "    plt.eventplot(raster_array_dR[i],linelengths = 0.1)\n",
    "    plt.xlim((1,len(raster_array_dR[0])))\n",
    "    plt.title(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BEHAVIOUR ANALYSIS WITH NEURAL ACTIVITY\n",
    "---------------------------------------------\n",
    "These cells plot neural activity and behaviour together to allow comparision between neural activity and behaviour     \n",
    "Most of this step still needs to be done by hand unfortunately..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input Behaviour Arrays\n",
    "\n",
    "#behaviour array: [frame behaviour turns on,frame off,on,off,on,... etc]\n",
    "behaviour_frames = []\n",
    "\n",
    "#fill with numbered behaviourws in order they occur\n",
    "behaviours = []\n",
    "\n",
    "#fill with colours corresponding to numbered behaviours\n",
    "colours=['blue','green']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display Neural Activity with Behaviour\n",
    "\n",
    "plt.figure(1)\n",
    "fig, ax = plt.subplots()\n",
    "ax.margins(0.02)\n",
    "for behav in range(len(behaviour_frames)-1):\n",
    "    colour_face = colours[behaviours[behav]]\n",
    "    ax.axvspan(behaviour_frames[behav],behaviour_frames[behav+1], facecolor = colour_face, alpha = 0.2)\n",
    "for i in range(len(intensities)):\n",
    "    plt.plot(intensities[i])\n",
    "plt.title('Raw Intensities plotted with CB and RP behaviour (CB=green)')\n",
    "plt.xlabel('Frame')\n",
    "plt.ylabel('Intensity')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(2)\n",
    "fig, ax = plt.subplots()\n",
    "ax.margins(0.02)\n",
    "for behav in range(len(behaviour_frames)-1):\n",
    "    colour_face = colours[behaviours[behav]]\n",
    "    ax.axvspan(behaviour_frames[behav],behaviour_frames[behav+1], facecolor = colour_face, alpha = 0.2)\n",
    "for i in range(len(detrended)):\n",
    "    plt.plot(detrended[i])\n",
    "plt.title('Processed Intensities plotted with CB and RP behaviour (CB=green)')\n",
    "plt.xlabel('Frame')\n",
    "plt.ylabel('Calcium Signal Intensities Detrended')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(3)\n",
    "fig, ax = plt.subplots()\n",
    "ax.margins(0.02)\n",
    "for behav in range(len(behaviour_frames)-1):\n",
    "    colour_face = colours[behaviours[behav]]\n",
    "    ax.axvspan(behaviour_frames[behav],behaviour_frames[behav+1], facecolor = colour_face,alpha = 0.2)\n",
    "plt.eventplot(raster_array_dR,linelengths = 0.6)\n",
    "plt.xlim((1,len(raster_array_dR[0])))\n",
    "plt.ylabel('Neuron')\n",
    "plt.xlabel('Frame')\n",
    "plt.title('Raster Plot of Neural Activity of Hydra Plotted with Behaviour')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CORRELATION AND INTERPRETATION OF DATA\n",
    "-----------------------------------\n",
    "The following cells work to group neurons together into ensembles, display various froms of correlation data presentation, and correlate each neuron to different types of behaviour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input Correlation Threshold to be Used to Group Neurons**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Dendrogram (can change method between ward, average, etc)\n",
    "CaSignal_norm = spikes_signal_dR\n",
    "plt.figure(figsize=(20, 20))  \n",
    "plt.title(\"Dendrograms\")  \n",
    "dend = shc.dendrogram(shc.linkage(CaSignal_norm, method='ward'),leaf_font_size=10,color_threshold = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CaSignal_norm = spikes_signal_dR\n",
    "df = pd.DataFrame(np.transpose(CaSignal_norm))\n",
    "plt.figure(figsize=(20, 20))  \n",
    "plt.title(\"Dendrograms\")\n",
    "palette = ['g','r','c','m','y','chartreuse','burlywood','DeepPink','orange']\n",
    "shc.set_link_color_palette(palette)\n",
    "dend = shc.dendrogram(shc.linkage(df.corr(), method='ward'),leaf_font_size=10,color_threshold = 3.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cluster_info = get_cluster_classes(dend)\n",
    "get_cluster_classes(dend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mylist = raster_array_dR\n",
    "myorder = dend['leaves']\n",
    "mylist = [mylist[i] for i in myorder]\n",
    "cluster_info = get_cluster_classes(dend)\n",
    "plt.figure(figsize=(30, 30))\n",
    "for col in set(dend['color_list']):\n",
    "    if col != 'b':\n",
    "        for row in cluster_info[col]:\n",
    "            plt.axhline(y=dend['leaves'].index(int(row)), color = col, alpha = 0.2, linewidth=5)\n",
    "\n",
    "for behav in range(len(behaviour_frames)-1):\n",
    "    colour_face = colours[behaviours[behav]]\n",
    "    plt.axvspan(behaviour_frames[behav],behaviour_frames[behav+1], facecolor = colour_face,alpha = 0.2)\n",
    "    \n",
    "plt.eventplot(mylist,linelengths = 0.4)\n",
    "plt.xlim((1,len(raster_array_dR[0])))\n",
    "plt.ylabel('Neuron')\n",
    "plt.xlabel('Frame')\n",
    "plt.title('Raster Plot of Neural Activity Sorted by Cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### **Input Number of Clusters Based on Results from Dendogram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#extract and view neurons from each cluster \n",
    "\n",
    "#number of clusters chosen from examination of dendogram\n",
    "#number_of_clusters = 7\n",
    "\n",
    "# use this function for Eucledian dendrograms\n",
    "#clusters = give_cluster_assigns(pd.DataFrame(np.transpose(CaSignal_norm)), number_of_clusters, transpose=True)\n",
    "#clusters = clusters.values\n",
    "\n",
    "\n",
    "# Use this instead for Correlation dendrograms\n",
    "\n",
    "# manually set the colors from the dendrogram\n",
    "cluster_colors = palette\n",
    "\n",
    "clusters = np.zeros((len(raster_array_dR),), dtype=int)\n",
    "number_of_clusters = 0\n",
    "for col in set(dend['color_list']):\n",
    "    if col != 'b':\n",
    "        number_of_clusters += 1\n",
    "        for row in cluster_info[col]:\n",
    "            clusters[int(row)] = cluster_colors.index(col)+1\n",
    "   \n",
    "                     \n",
    "#plot specific cluster's neurons traces\n",
    "\n",
    "cluster_to_view = 0\n",
    "average_intensities = np.zeros(number_of_clusters)\n",
    "cluster_sizes = np.zeros(number_of_clusters)\n",
    "\n",
    "for i in range(len(clusters)):\n",
    "    average_intensities[clusters[i]-1] += np.sum(Foopsi_ca[i])/len(vid)\n",
    "    cluster_sizes[clusters[i]-1] += 1\n",
    "    if clusters[i] == cluster_to_view:\n",
    "        plt.figure(i-1)\n",
    "        plt.title(i)\n",
    "        plt.eventplot(raster_array_dR[i])\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "average_intensities = average_intensities/cluster_sizes\n",
    "plt.bar(range(1,number_of_clusters+1),average_intensities)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Super impose locations of neurons in specified Cluster onto video frame\n",
    "\n",
    "os.chdir('C:\\\\Users\\\\rylab\\\\Desktop\\\\AliA\\\\Best 10X\\\\')\n",
    "cwd = os.getcwd()\n",
    "#os.mkdir('test')\n",
    "os.chdir('test')\n",
    "\n",
    "color_codes = ['']*len(raster_array_dR)\n",
    "for i in range(len(color_codes)):\n",
    "    for color,track in cluster_info.items():\n",
    "        temp = str(i)\n",
    "        if temp in track:\n",
    "            color_codes[i] = str(color)\n",
    "                \n",
    "cluster_to_view = [1,2,3,4,5,6,7,8,9]\n",
    "frame_for_cluster = 0\n",
    "number_of_frames = len(vid)\n",
    "video_for_cluster = red_vid\n",
    "title_for_cluster = 'Cluster Positions'\n",
    "\n",
    "Super_impose_cluster(video = video_for_cluster, frame_to_view = frame_for_cluster, \\\n",
    "                     posit_corrected = posit_corrected, clusters = clusters, cluster_to_view = cluster_to_view, \\\n",
    "                     Title = title_for_cluster, sequence = number_of_frames, color_codes = color_codes)\n",
    "\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.transpose(CaSignal_norm))\n",
    "plt.matshow(df.corr())\n",
    "plt.show()\n",
    "corr = df.corr()\n",
    "fig, ax = plt.subplots(figsize=(30,30))\n",
    "sns.heatmap(corr, \n",
    "            xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ClusterMap\n",
    "#change figure size to see all labels if necessary\n",
    "\n",
    "df = pd.DataFrame(np.transpose(CaSignal_norm))\n",
    "\n",
    "# Draw the full plot\n",
    "sns.clustermap(df.corr(), center=0, cmap=\"coolwarm\",linewidths=.75, figsize=(20,20), method = 'ward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarized = (raster_array_dR > 0).astype(int)\n",
    "with open('test.txt', 'w') as f:\n",
    "    for j in range(binarized.shape[1]):\n",
    "        f.write(\"> Frame #\" + str(j) + \"\\n\")\n",
    "        temp = ''\n",
    "        for i in range(binarized.shape[0]):\n",
    "            if binarized[i][j] == 1:\n",
    "                temp += 'A'\n",
    "            else:\n",
    "                temp += 'M'\n",
    "        #print(temp)\n",
    "        f.write(temp)\n",
    "        f.write(\"\\n\\n\")\n",
    "        \n",
    "with open('hydra_raster.txt', 'w') as f:\n",
    "    for j in range(binarized.shape[1]):\n",
    "        temp = ''\n",
    "        for i in range(binarized.shape[0]):\n",
    "            if binarized[i][j] == 1:\n",
    "                temp += '1'\n",
    "            else:\n",
    "                temp += '0'\n",
    "        f.write(temp)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Investigate Correlations from ClusterMap\n",
    "\n",
    "#input neurons to view\n",
    "neuron_1 = 71\n",
    "neuron_2 = 36\n",
    "\n",
    "plt.figure(1)\n",
    "fig, ax = plt.subplots()\n",
    "ax.margins(0.02)\n",
    "for behav in range(len(behaviour_frames)-1):\n",
    "    colour_face = colours[behaviours[behav]]\n",
    "    ax.axvspan(behaviour_frames[behav],behaviour_frames[behav+1], facecolor = colour_face,alpha = 0.2)\n",
    "plt.plot(detrended[neuron_1])\n",
    "plt.plot(detrended[neuron_2])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(2)\n",
    "plt.title(neuron_1)\n",
    "plt.eventplot(raster_array_dR[neuron_1],linelengths = 0.6)\n",
    "plt.xlim((1,len(raster_array_dR[0])))\n",
    "plt.show()\n",
    "\n",
    "plt.figure(3)\n",
    "plt.title(neuron_2)\n",
    "plt.eventplot(raster_array_dR[neuron_2],linelengths = 0.6)\n",
    "plt.xlim((1,len(raster_array_dR[0])))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Single neuron investigation\n",
    "\n",
    "neuron_to_investigate = 50\n",
    "frame_to_investigate = 1606\n",
    "\n",
    "single_neuron_investigation(neuron_to_investigate, CaSignal, vid, frame_to_investigate, dim, posit_corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Data**\n",
    "===============\n",
    "**Optional Cells to Save Results**        \n",
    "Run these cells to save the data as a .csv         \n",
    "Input file name and path where file should be saved           \n",
    "**On Windows: Paths still need to start with 'r'**              \n",
    "e.g. r'C:\\Users\\rylab\\Documents\\path to your folder\\title.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Raw GCamp Intensity Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Raw GCamp Intensity data as a .csv \n",
    "\n",
    "# Save_Path = r'C:\\Users\\rylab\\Documents\\Noah2019_desktop\\Columbia_Project\\hydra_Vids\\2-colour\\single_cell_intensity_behaviour_longclip.csv'\n",
    "\n",
    "# intensity_dataframe = pd.DataFrame(intensities)\n",
    "# intensity_dataframe.to_csv(Save_Path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save CaSignal Intensity Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save CaSignal data to .csv\n",
    "\n",
    "# Ca_save_path = r'C:\\Users\\rylab\\Documents\\Noah2019_desktop\\Columbia_Project\\hydra_Vids\\2-colour\\single_cell_CaSig.csv'\n",
    "\n",
    "# intensity_dataframe = pd.DataFrame(CaSignal)\n",
    "# intensity_dataframe.to_csv(Ca_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sava Detrended Intensity Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save detrended data to .csv\n",
    "\n",
    "# dR_detrend_save_path = r'C:\\Users\\rylab\\Documents\\Noah2019_desktop\\Columbia_Project\\hydra_Vids\\2-colour\\single_cell_detrend.csv'\n",
    "\n",
    "# dfintensity_dataframe = pd.DataFrame(detrended)\n",
    "# dfintensity_dataframe.to_csv(dR_detrend_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Foopsi De-noised Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #save Foopsi de-noised data to .csv\n",
    "\n",
    "# Ca_denoised_path = r'C:\\Users\\rylab\\Documents\\Noah2019_desktop\\Columbia_Project\\Project_Behaviour_and_Neural_Activity\\Single_Cell_Analysis_Neural\\Single_Cell_Data\\VID1_oct_4_3hz\\Results\\denoised_neuraldata.csv'\n",
    "\n",
    "# ca_dataframe = pd.DataFrame(Foopsi_ca)\n",
    "# ca_dataframe.to_csv(Ca_denoised_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Raster Plot Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save raster data to .csv (needs to be reformatted from event plot form first)\n",
    "\n",
    "# raster_save_path = r'C:\\Users\\rylab\\Documents\\Noah2019_desktop\\Columbia_Project\\hydra_Vids\\2-colour\\single_cell_rasterb1.csv'\n",
    "\n",
    "# raster_array_pred = np.zeros((len(raster_array_dR),len(raster_array_dR[1])))\n",
    "# for i in range(len(spikes_signal_dR)):\n",
    "#     for j in range(len(spikes_signal_dR[i])):\n",
    "#         if max(spikes_signal_dR[i]) > 0:\n",
    "#             if spikes_signal_dR[i][j] >= spike_thresh_dR: #*np.mean(spikes_signal_dR[i]):\n",
    "#                 raster_array_pred[i][j] = 1\n",
    "\n",
    "# raster_dataframe = pd.DataFrame(raster_array_pred)\n",
    "# raster_dataframe.to_csv(raster_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Behaviour Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Behaviour Array tp .csv\n",
    "# behaviour_Save_Path = r\"C:\\Users\\rylab\\Downloads\\behav_array.csv\"\n",
    "\n",
    "# behav_array = np.zeros(len(vid))\n",
    "# for i in range(len(behaviours)):\n",
    "#     behav_array[behaviour_frames[i]:behaviour_frames[i+1]] = behaviours[i]\n",
    "    \n",
    "# behaviour_dataframe = pd.DataFrame(behav_array)\n",
    "# behaviour_dataframe.to_csv(behaviour_Save_Path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation Cells**\n",
    "====================\n",
    "These cells allow for the evaluation of the tuning of various functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate Polynomial Detrending Parameters** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate ploynomail detrending\n",
    "neuron_test_detrend = 10\n",
    "#polynomial degree of 15-17 gives good results - but tune for new data!\n",
    "polynomial_test_degree  = 12\n",
    "detrend_one = detrend(smooth_intensities[neuron_test_detrend],polynomial_test_degree)\n",
    "plt.figure(1)\n",
    "plt.plot(detrend_one, c='b')\n",
    "plt.plot(smooth_intensities[neuron_test_detrend], c = 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluste ICA vs Ratiometric Artefact Removal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New ICA vs Ratiometric\n",
    "\n",
    "a, b = np.asanyarray(norm_Data(intensities[12])), np.asanyarray(norm_Data(intensities_red[12]))\n",
    "plt.plot(a, c = 'g')\n",
    "plt.title('Raw Intensities of GCaMP7 (Green) Channel')\n",
    "plt.xlabel('Frames')\n",
    "plt.ylabel('Normalised Intensity')\n",
    "plt.show()\n",
    "plt.plot(b, c = 'r')\n",
    "plt.title('Raw Intensities of tdTomato (Red) Channel')\n",
    "plt.xlabel('Frames')\n",
    "plt.ylabel('Normalised Intensity')\n",
    "plt.show()\n",
    "\n",
    "c = (a+1)/(b+1)\n",
    "plt.plot(c)\n",
    "plt.title('Ratiometric Correction of Motion Artefacts')\n",
    "plt.xlabel('Frames')\n",
    "plt.ylabel('Intensity Ratio')\n",
    "plt.show()\n",
    "\n",
    "print(min(a))\n",
    "print(min(b))\n",
    "\n",
    "ica_g = ICAdecorr([a],[b],0.05, 10)\n",
    "plt.plot(ica_g[0])\n",
    "plt.title('ICA Correction of Motion Artefacts')\n",
    "plt.xlabel('Frames')\n",
    "plt.ylabel('Normalised Intensity')\n",
    "# plt.show()\n",
    "# plot_all(p)\n",
    "# print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate FOOPSI Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuning for FOOPSI \n",
    "\n",
    "tuning_thresh_foopsi = 0.001\n",
    "\n",
    "evaluation_neuron_foopsi = 10\n",
    "spikes_signal_tuning = FOOPSI_all(normalize(detrended))\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(detrended[evaluation_neuron_foopsi])\n",
    "plt.title('detrended signal for Specified Neuron')\n",
    "plt.ylabel('Calcium Signal Detrended Intensity')\n",
    "plt.xlabel('Frame Number')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(spikes_signal_dR[evaluation_neuron_foopsi])\n",
    "plt.title('FOOPSI Results for Specified Neuron')\n",
    "plt.ylabel('Estimated Neural Activity')\n",
    "plt.xlabel('Frame Number')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate use of ICA or DeltaR/R to separate signal from noise**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ICA artifact removal comparison cell\n",
    "ICA_test_neuron = 9\n",
    "R = intensities_red\n",
    "G = intensities\n",
    "\n",
    "a = decorrelateNeuronsICA(R, G, 0.2)\n",
    "\n",
    "plt.plot(G[ICA_test_neuron], c = 'g')\n",
    "plt.plot(R[ICA_test_neuron], c = 'r')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(a[ICA_test_neuron], c = 'g')\n",
    "plt.title('ICA')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(deltaR[ICA_test_neuron], c = 'r')\n",
    "plt.title('DR/R')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find Raster Plot from Non-DR/R data**    \n",
    "Recalculates the spikes from the raw data and plots the results      \n",
    "Evaluates best input to use with FOOPSI Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raster with non-dR/R - Compare Rasters from different input data\n",
    "\n",
    "Raw_filt, _ = np.asanyarray(filt_nematocytes(intensities, 5, positions))\n",
    "\n",
    "raw_smooth = smoother(Raw_filt, 5)\n",
    "\n",
    "df_f_signal = np.asanyarray(df_f(raw_smooth))\n",
    "\n",
    "\n",
    "plt.figure(1)\n",
    "for i in range(len(raw_smooth)):\n",
    "    plt.plot(raw_smooth[i])\n",
    "plt.title('Intensity Plot Raw smooth')\n",
    "plt.xlabel('Frame')\n",
    "plt.ylabel('Intensity')\n",
    "plt.show()\n",
    "\n",
    "#Create Raster Plot using CAIMAN's FOOPSI function\n",
    "#foopsi (used on non-df/f data)\n",
    "spikes_signal = np.zeros((len(Raw_filt),len(Raw_filt[1])))\n",
    "for i in range(len(Raw_filt)):\n",
    "    ca_foopsi,cb,b1,g,c1,spikes_foopsi,lam = deconv.constrained_foopsi(Raw_filt[i],p=2)\n",
    "    spikes_signal[i] = spikes_foopsi\n",
    "    \n",
    "#foopsi (used on df/f data)\n",
    "spikes_signal_df = np.zeros((len(df_f_signal),len(df_f_signal[1])))\n",
    "for i in range(len(df_f_signal)):\n",
    "    ca_foopsi,cb,b1,g,c1,spikes_foopsi,lam = deconv.constrained_foopsi(df_f_signal[i],p=2)\n",
    "    spikes_signal_df[i] = spikes_foopsi\n",
    "\n",
    "#threshold to find spikes\n",
    "spike_thresh = 0.3\n",
    "\n",
    "raster_array = np.zeros((len(Raw_filt),len(Raw_filt[1])))\n",
    "for i in range(len(spikes_signal)):\n",
    "    for j in range(len(spikes_signal[i])):\n",
    "        if spikes_signal[i][j] >= spike_thresh*max(spikes_signal[i]):\n",
    "            raster_array[i][j] = j\n",
    "\n",
    "raster_array_df = np.zeros((len(df_f_signal),len(df_f_signal[1])))\n",
    "for i in range(len(spikes_signal_df)):\n",
    "    for j in range(len(spikes_signal_df[i])):\n",
    "        if spikes_signal_df[i][j] >= spike_thresh*max(spikes_signal_df[i]):\n",
    "            raster_array_df[i][j] = j\n",
    "\n",
    "#Plot raster for base data\n",
    "#zero values from way array was made array give large syncronous train at start of the signal - should fix (.append method?)\n",
    "plt.figure(3)\n",
    "plt.eventplot(raster_array,linelengths = 0.5)\n",
    "plt.title('Raster Plot of All Neurons (raw intensities)')\n",
    "plt.xlabel('Frame Number')\n",
    "plt.ylabel('Neuron')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(4)\n",
    "plt.eventplot(raster_array_df,linelengths = 0.5)\n",
    "plt.title('Raster Plot of All Neurons (df/f intensities)')\n",
    "plt.xlabel('Frame Number')\n",
    "plt.ylabel('Neuron')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternative Clustering Visualisation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clustering Data - evaluate clustering with a cluster map (provides some extra visualisation if you want it but I prefer other methods)\n",
    "#Input Number of Clusters Based on Results from Dendogram\n",
    "\n",
    "eucdist = cdist(CaSignal_norm,CaSignal_norm)\n",
    "cluster = AgglomerativeClustering(n_clusters=number_of_clusters, affinity='euclidean')\n",
    "cluster.fit_predict(CaSignal_norm)\n",
    "plt.figure(figsize=(10, 7))  \n",
    "plt.scatter(eucdist[:,1], eucdist[:,0],c=cluster.labels_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate Raster Reshaping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Evaluate Raster Reshaping step for saving as csv\n",
    "\n",
    "# raster_reshape_test_neuron = 5\n",
    "\n",
    "# plt.plot(raster_array_pred[raster_reshape_test_neuron], color = 'r')\n",
    "# plt.eventplot(raster_array_dR[raster_reshape_test_neuron])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate Neuron Tracking**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 57\n",
    "_,_,_,display = SingleCellIntensity(neuron = n, video = vid, positions = posit_corrected, dimentionROI = dim, Circle_radius = 4, distance_threshold = 4, display_on = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Tracked Neurons**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(display)):\n",
    "#     plt.imshow(display[i])\n",
    "#     title = 'neuron_' + str(i) + '.tif'\n",
    "#     plt.savefig(str(title), format = 'tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimental Cells\n",
    "==============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raster using peak detection function - needs tuning...\n",
    "\n",
    "neuron_for_peaks = 50\n",
    "distance_between_peaks = 10\n",
    "prominance_of_peaks = 0.05\n",
    "\n",
    "a,b = sp.signal.find_peaks(detrended[neuron_for_peaks], distance = distance_between_peaks, prominence = prominance_of_peaks)\n",
    "plt.figure(1)\n",
    "plt.plot(detrended[neuron_for_peaks])\n",
    "plt.plot(a, detrended[neuron_for_peaks][a], 'x')\n",
    "plt.show()\n",
    "\n",
    "raster2 = np.zeros((len(detrended), len(detrended[1])))\n",
    "for i in range(len(detrended)):\n",
    "    peaks,_ = sp.signal.find_peaks(detrended[i], distance = distance_between_peaks, prominence = prominance_of_peaks)\n",
    "    for j in range(len(detrended[i])):\n",
    "        for k in range(len(peaks)):\n",
    "            raster2[i][peaks[k]] = 1\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(raster2[neuron_for_peaks])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#frequency filtering\n",
    "#sampling rate = 3Hz\n",
    "#hmm doesnt seem to work well at all\n",
    "\n",
    "neurons = 10\n",
    "\n",
    "frqs = np.fft.fft(detrended[neuron])\n",
    "xax = np.arange(0,6000, 6000/(len(detrended[0])))\n",
    "plt.figure(1)\n",
    "plt.title('Fourier Spectrum')\n",
    "plt.plot(abs(frqs.real))\n",
    "\n",
    "\n",
    "#freqs adjusted\n",
    "filter_block = np.ones(len(detrended[0]))\n",
    "low_pass_cut = 30\n",
    "filter_block[low_pass_cut:len(filter_block)-low_pass_cut] = 0\n",
    "#filter_block[len(filter_block) - 80: len(filter_block) - 55] = 1\n",
    "plt.plot(filter_block)\n",
    "plt.show()\n",
    "new_freqs = np.fft.ifft(frqs*filter_block)\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(new_freqs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #independant component analysis to separate noise - single neuron\n",
    "\n",
    "# ica_test_neuron = 9\n",
    "# window = 5\n",
    "\n",
    "# data_green = [intensities[ica_test_neuron]]\n",
    "# filtered_data_g = smoother(data_green,window)\n",
    "# filtered_data_g = np.transpose(detrend(np.transpose(filtered_data_g), 17))\n",
    "# plt.figure(1)\n",
    "# plt.plot(filtered_data_g[0],c='g')\n",
    "# # plt.plot(data_green[0],'r')\n",
    "\n",
    "# data_red = [intensities_red[ica_test_neuron]]\n",
    "# filtered_data_r = smoother(data_red,window)\n",
    "# filtered_data_r = np.transpose(detrend(np.transpose(filtered_data_r), 17))\n",
    "# plt.figure(2)\n",
    "# plt.plot(filtered_data_r[0],c='r')\n",
    "# # plt.plot(data_red[0],'r')\n",
    "# plt.show()\n",
    "\n",
    "# X = np.c_[filtered_data_g[0],filtered_data_r[0]]\n",
    "# print(X.shape)\n",
    "# X = X.reshape(len(filtered_data_g[0]),2)\n",
    "# print(X.shape)\n",
    "# # scaler= StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "# # X = scaler.fit_transform(X)\n",
    "# ica = FastICA(n_components = 2, random_state = None)\n",
    "# A = ica.fit_transform(X)\n",
    "\n",
    "# plt.figure(3)\n",
    "# plt.plot(X[:,0], c='g')\n",
    "# plt.plot(X[:,1], c='r')\n",
    "# plt.plot(data_green, c='b')\n",
    "# plt.plot(data_red, c='y')\n",
    "# plt.figure(4)\n",
    "# plt.plot(A[:,0])\n",
    "# plt.plot(A[:,1])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Correlation Between Neural Activity and Behaviour\n",
    "# #Method finds change in neural activity between CB and RP\n",
    "\n",
    "# #select neuron to observe\n",
    "# neuron = 44\n",
    "\n",
    "# #select lenght of sub sequences (will depend on number of frames behaviour takes up)\n",
    "# seqlen = 100\n",
    "\n",
    "# df_on = smooth_intensities[neuron][301:565] + smooth_intensities[neuron][991:1076]\n",
    "# df_ons = []\n",
    "# for i in range(int(len(df_on)/seqlen)):\n",
    "#     df_ons.append(df_on[i*seqlen:(i*seqlen)+seqlen])\n",
    "\n",
    "# df_off = smooth_intensities[neuron][0:301] + smooth_intensities[neuron][565:991] + smooth_intensities[neuron][1076: len(smooth_intensities[0])]\n",
    "# df_offs = []\n",
    "# for i in range(int(len(df_off)/seqlen)):\n",
    "#     df_offs.append(df_off[i*seqlen:(i*seqlen)+seqlen])\n",
    "    \n",
    "# #find average of on signal\n",
    "# avg_on = []\n",
    "# for i in range(len(df_ons[0])):\n",
    "#     values = []\n",
    "#     for j in range(len(df_ons)):\n",
    "#         values.append(df_ons[j][i]) \n",
    "#     avg_on.append(np.mean(values))\n",
    "\n",
    "# #find average of off signal\n",
    "# avg_off = []\n",
    "# for i in range(len(df_offs[0])):\n",
    "#     values = []\n",
    "#     for j in range(len(df_offs)):\n",
    "#         values.append(df_offs[j][i]) \n",
    "#     avg_off.append(np.mean(values))\n",
    "\n",
    "# #correlation\n",
    "# corr_on_off = np.corrcoef(avg_off,avg_on)[0,1]\n",
    "# print('Pearson Correlation Coeff: ', corr_on_off)\n",
    "\n",
    "# #if correlation is very low, neurons change activity patterns during behaviour!!\n",
    "# if abs(corr_on_off) < 0.5:\n",
    "#     print('Neuron Changes Activity During Behaviour')\n",
    "# else:\n",
    "#     print('Neuron Does Not Change Activity During Behaviour')\n",
    "    \n",
    "# plt.plot(avg_on)\n",
    "# plt.plot(avg_off)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
